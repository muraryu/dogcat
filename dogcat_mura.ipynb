{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogcat_mura.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muraryu/dogcat/blob/master/dogcat_mura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlyuWq63uwTM",
        "colab_type": "text"
      },
      "source": [
        "Google Colabの場合のみ最初に実行する\n",
        "\n",
        "ここではGoogleドライブから必要なデータを持ってくる(直接アップロードでも良いが面倒。KaggleAPIキーも面倒。)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpPRPlu0xPeQ",
        "colab_type": "code",
        "outputId": "04805b7e-54b8-4ff7-9a77-fbe5647661bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# 事前にGoogleドライブに必要なデータを保存しておく\n",
        "# => train_label.csv, sample_submission.csv, train.zip, test.zip\n",
        "\n",
        "# Googleドライブのマウント\n",
        "# 実行後、標準出力のURLをクリックしてアクセス許可＆認証コードを取得し、’Enter your authorization code:’に入力する\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Googleドライブに保存しておいた重いデータのみローカルにコピー\n",
        "!cp \"drive/My Drive/dogcat/input/train.zip\" ./\n",
        "!cp \"drive/My Drive/dogcat/input/test.zip\" ./\n",
        "!cp \"drive/My Drive/dogcat/input/original/test_original.zip\" ./\n",
        "\n",
        "# 解凍\n",
        "# 標準出力を '> /dev/null' で捨てないとブラウザが固まるため注意する\n",
        "# 同様に解凍後のフォルダを左のファイルビューで展開しないこと(ファイルが多すぎて固まる)\n",
        "!mkdir ./train\n",
        "!mkdir ./test\n",
        "!mkdir ./test_original\n",
        "!unzip train.zip -d ./train > /dev/null\n",
        "!unzip test.zip -d ./test > /dev/null\n",
        "!unzip test_original.zip -d ./test_original > /dev/null\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9B-6y2p59zZ",
        "colab_type": "code",
        "outputId": "ee8e9b7e-5bd0-42c3-8725-0a1a21b2e528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# パス　実行環境ごとに書き換え\n",
        "train_dir = 'train/'\n",
        "test_dir = 'test/'\n",
        "test_original_dir = 'test_original/'\n",
        "train_pre_dir = 'train_pre/'\n",
        "test_pre_dir = 'test_pre/'\n",
        "test_original_pre_dir = 'test_original_pre/'\n",
        "train_labels_path = 'drive/My Drive/dogcat/input/train_label.csv'\n",
        "sample_submission_path = 'drive/My Drive/dogcat/input/sample_submission.csv'\n",
        "sample_submission_original_path = 'drive/My Drive/dogcat/input/original/sample_submission_original.csv'\n",
        "gradcam_dir = 'drive/My Drive/dogcat/GradCAM++/'\n",
        "model_check_point_dir = 'drive/My Drive/dogcat/model/'\n",
        "\n",
        "# Google Colaboratory環境であることを示すフラグ\n",
        "google_colab_flag = []\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofv8fEIltxB0",
        "colab_type": "text"
      },
      "source": [
        "##################\n",
        "\n",
        "**ここからKaggle共通**\n",
        "##################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b43dpyJyxAUR",
        "colab_type": "code",
        "outputId": "b080015d-54b7-4783-eda4-5a2bfe474d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "# Google Colaboratory環境ではない場合、Kaggleのファイルパスを使用\n",
        "if 'google_colab_flag' in locals():\n",
        "    print('Using file path for Google Colaboratory.')\n",
        "else:\n",
        "    print('Using file path for Kaggle.')\n",
        "    train_dir = '../input/train/'\n",
        "    test_dir = '../input/test/'\n",
        "    train_pre_dir = '../train_pre/'\n",
        "    test_pre_dir = '../test_pre/'\n",
        "    train_labels_path = '../input/train_label.csv'\n",
        "    sample_submission_path = '../input/sample_submission.csv'\n",
        "    gradcam_dir = '../GradCAM++'\n",
        "    model_check_point_dir = './model/'\n",
        "\n",
        "# %% [markdown]\n",
        "# 事前に画像サイズを統一しておくことで学習時間を短縮します。 \n",
        "\n",
        "# %% [markdown]\n",
        "# ********# Dogs vs Cats Recognition: InClass\n",
        "# # # # # # # # これは [Dogs vs Cats Recognition: InClass](https://www.kaggle.com/c/dog-cat-recognition/overview)のBase kernelです。  \n",
        "# # # # # # # # PythonのDeep learning用フレームワーク keras を使用し、基本的なCNNモデルを構築します。  \n",
        "# # # # # # # # またkerasの ImageDataGenerator を使用し、画像の水増し (Data Augmentation) を行えるようにしているのがポイントです。\n",
        "\n",
        "# %% [markdown]\n",
        "# ----\n",
        "# # # # # # # # Import, Config, Utilities\n",
        "# # # # # # # # まず初めに下記を行います。\n",
        "# # # # # # # # - 必要なライブラリのImport\n",
        "# # # # # # # # - 各種Config (乱数seed設定, 学習パラメタ...etc)\n",
        "# # # # # # # # - Utility関数の定義\n",
        "\n",
        "# %% [code]\n",
        "# 必要なライブラリのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D, BatchNormalization, Activation\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "\n",
        "from IPython.display import HTML\n",
        "import base64\n",
        "\n",
        "# 追加\n",
        "import math\n",
        "from keras.applications import *\n",
        "import traceback\n",
        "\n",
        "# %% [code]\n",
        "# 関数\n",
        "\n",
        "# 学習曲線の描画関数\n",
        "def show_fit_result(history):\n",
        "    plt.figure(figsize=(16,4))\n",
        "    \n",
        "    # plot accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['acc'], label='trn_acc', marker='.')\n",
        "    plt.plot(history.history['val_acc'], label='val_acc', marker='.')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "    \n",
        "    # plot loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='trn_loss', marker='.')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss', marker='.')\n",
        "    plt.title('Crossentropy')\n",
        "    plt.legend()\n",
        "\n",
        "def CNN(input_shape, kernel_size, max_pooling_size, act_func, conv2d_filters, drop_ratio, num_layer, num_dence_layer, num_conv2d_layer):\n",
        "    # input_shape      : 入力次元数 \n",
        "    # kernel_size      : 畳み込み層のフィルタサイズ\n",
        "    # max_pooling_size : Pooling層のフィルタサイズ\n",
        "    # act_func         : 中間層の活性化関数\n",
        "    # drop_ratio       : Dropoutの割合\n",
        "    \n",
        "    # kernel initializers\n",
        "    gl_init = glorot_uniform(1111)\n",
        "    \n",
        "    # Sequentialモデルのインスタンス作成\n",
        "    model = Sequential()\n",
        "\n",
        "    \"\"\"\n",
        "    for i in range(num_layer):\n",
        "        for j in range(num_conv2d_layer):\n",
        "            if i == 0 and j == 0:\n",
        "                model.add(Conv2D(conv2d_filters, kernel_size, activation='relu', input_shape=input_shape, kernel_initializer=gl_init))\n",
        "            else:\n",
        "                model.add(Conv2D(conv2d_filters, kernel_size, activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "        model.add(Dropout(drop_ratio, seed=1111))\n",
        "\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "        \n",
        "    for i in range(num_dence_layer):\n",
        "        model.add(Dense(int(1024/(2**i)), activation='relu', kernel_initializer=gl_init))\n",
        "    # 出力層\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    model.add(Conv2D(64, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init, input_shape=input_shape))\n",
        "    model.add(Conv2D(64, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(128, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(128, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(256, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(256, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(256, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(256, activation='relu', kernel_initializer=gl_init))\n",
        "    model.add(Dropout(0.5, seed=1111))\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "    \"\"\"\n",
        "    \n",
        "    #conv_base = Xception(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = VGG16(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = VGG19(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    conv_base = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
        "    #conv_base = MobileNet(input_shape=input_shape, alpha=1.0, depth_multiplier=1, dropout=1e-3, include_top=False, weights='imagenet', pooling=None)\n",
        "    #conv_base = DenseNet201(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = NASNetLarge(input_shape=input_shape, include_top=False, weights='imagenet', pooling=None)\n",
        "    #conv_base = MobileNetV2(input_shape=input_shape, alpha=1.0, depth_multiplier=1, include_top=False, weights='imagenet', pooling=None)\n",
        "    \n",
        "    #conv_base.trainable = False\n",
        "    model.add(conv_base)\n",
        "#    model.add(Flatten())\n",
        "\n",
        "#    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(256))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dropout(0.5, seed=1111))\n",
        "    model.add(Dense(1, activation='sigmoid')) \n",
        "\n",
        "    \n",
        "    \"\"\"\n",
        "    # 畳み込み層、Pooling層、Dropoutの追加\n",
        "    model.add(Conv2D(64, kernel_size, padding='same', activation=act_func, input_shape=input_shape, kernel_initializer=gl_init))\n",
        "    model.add(MaxPool2D(pool_size=max_pooling_size))\n",
        "    model.add(Dropout(drop_ratio, seed=1111))\n",
        "    \n",
        "    # 畳み込み層、Pooling層、Dropoutの追加\n",
        "    for i in range(num_layer):    \n",
        "        model.add(Conv2D(64, kernel_size, padding='same', activation=act_func, kernel_initializer=gl_init))\n",
        "        model.add(MaxPool2D(pool_size=max_pooling_size))\n",
        "        model.add(Dropout(drop_ratio, seed=1111))\n",
        "\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    # 全結合層の追加\n",
        "    model.add(Dense(128, activation=act_func, kernel_initializer=gl_init))\n",
        "    \n",
        "    # 出力層\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "    \"\"\"\n",
        "    \n",
        "    return model\n",
        "    \n",
        "def logloss(true_label, predicted, eps=1e-15):\n",
        "    p = np.clip(predicted, eps, 1 - eps)\n",
        "    true_label = int(true_label)\n",
        "    if true_label == 1:\n",
        "        return -math.log(p)\n",
        "    else:\n",
        "        return -math.log(1 - p)\n",
        "\n",
        "def loglossavg(true_label_ary, predicted_ary):\n",
        "    s = 0\n",
        "    i = 0\n",
        "    print(true_label_ary)\n",
        "    print(predicted_ary)\n",
        "    for true_label in true_label_ary:\n",
        "        s += logloss(true_label, predicted_ary[i])\n",
        "        i += 1\n",
        "    return s/i\n",
        "\n",
        "# (参考)下記関数を使うと、予測結果のCSVファイルをCommitなしで取得できます。\n",
        "# https://www.kaggle.com/rtatman/download-a-csv-file-from-a-kernel\n",
        "# function that takes in a dataframe and creates a text link to  \n",
        "# download it (will only work for files < 2MB or so)\n",
        "def create_download_link(df, title = \"Download CSV file\", filename = \"submission.csv\"):  \n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
        "    html = html.format(payload=payload,title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "\n",
        "### **注意**\n",
        "# # # # # # 上記で乱数seedを固定することで、ある程度は実験の再現性が得られますが、完全ではありません。  \n",
        "# # # # # # (kernel編集中の学習結果とCommit後の学習結果が微妙に異なる)  \n",
        "# # # # # # これはNVIDIA製GPUにおける並列計算処理が非決定的であるためです。  \n",
        "# # # # # # 本kernelの最後にはCommitなしで予測結果のCSVをダウンロードする方法も記載していますので参考にしてください。\n",
        "\n",
        "# 乱数seedの固定 (kerasの学習結果の再現性確保)\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(1111)\n",
        "random.seed(1111)\n",
        "\n",
        "session_conf = tf.ConfigProto(\n",
        "    intra_op_parallelism_threads=1,\n",
        "    inter_op_parallelism_threads=1\n",
        ")\n",
        "\n",
        "tf.set_random_seed(1111)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# %% [code]\n",
        "# 変数\n",
        "\n",
        "value_space = {}\n",
        "\n",
        "# CNNパラメータ\n",
        "value_space[\"CNN_conv2d_filters\"] = [4,8,16,32,64,128,192,256,512,1024,2048,4096,8192]\n",
        "value_space[\"CNN_num_dence_layer\"] = [0,1,2,3,4,5,6,7]\n",
        "value_space[\"CNN_num_layer\"] = np.arange(0, 11, 1)\n",
        "value_space[\"CNN_kernel_size\"] = np.arange(1, 11, 1)\n",
        "value_space[\"CNN_act_func\"] = [\"softmax\", \"elu\", \"selu\", \"softplus\", \"softsign\", \"relu\", \"tanh\", \"sigmoid\", \"hard_sigmoid\", \"linear\"]\n",
        "value_space[\"CNN_max_pooling_size\"] = np.arange(2, 11, 1)\n",
        "value_space[\"CNN_drop_ratio\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"CNN_num_conv2d_layer\"] = [1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# target size\n",
        "value_space[\"width_x_height\"] = [32,64,96,128,192,512,320,384,448,512]\n",
        "value_space[\"batch_size\"] = [8,16,32,48,128,256,512,1024,2048]\n",
        "value_space[\"color_mode\"] = [\"grayscale\", \"rgb\"]\n",
        "\n",
        "# 学習画像前処理\n",
        "value_space[\"rotation_range\"] = np.arange(0, 181, 5)\n",
        "value_space[\"width_shift_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"height_shift_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"zoom_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"brightness_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"fill_mode\"] = [\"nearest\", \"reflect\", \"wrap\"]\n",
        "\n",
        "# ベクトル初期化\n",
        "candidate_vector = {\n",
        "    \"CNN_conv2d_filters\":5,\n",
        "    \"CNN_num_dence_layer\":3,\n",
        "    \"CNN_num_layer\":4,\n",
        "    \"CNN_kernel_size\":2,\n",
        "    \"CNN_act_func\":5,\n",
        "    \"CNN_max_pooling_size\":0,\n",
        "    \"CNN_drop_ratio\":0,\n",
        "    \"CNN_num_conv2d_layer\":0,\n",
        "\n",
        "    \"width_x_height\":5,\n",
        "    \"batch_size\":0,\n",
        "    \"color_mode\":1,\n",
        "\n",
        "    \"rotation_range\":10,\n",
        "    \"width_shift_range\":2,\n",
        "    \"height_shift_range\":2,\n",
        "    \"zoom_range\":0,\n",
        "    \"brightness_range\":5,\n",
        "    \"fill_mode\":0,\n",
        "    }\n",
        "\n",
        "# 固定変数リスト\n",
        "fixed_variable = [\n",
        "    \"CNN_conv2d_filters\",\n",
        "    \"CNN_num_dence_layer\",\n",
        "    \"CNN_num_layer\",\n",
        "    \"CNN_kernel_size\",\n",
        "    \"CNN_act_func\",\n",
        "    \"CNN_max_pooling_size\",\n",
        "    \"CNN_drop_ratio\",\n",
        "    \"CNN_num_conv2d_layer\",\n",
        "\n",
        "    \"width_x_height\",\n",
        "    \"batch_size\",\n",
        "    \"color_mode\",\n",
        "\n",
        "    \"rotation_range\",\n",
        "    \"width_shift_range\",\n",
        "    \"height_shift_range\",\n",
        "    \"zoom_range\",\n",
        "    \"brightness_range\",\n",
        "    \"fill_mode\",\n",
        "]\n",
        "\n",
        "\n",
        "# number of epoch\n",
        "NUM_EPOCH = 0\n",
        "\n",
        "# %% [code]\n",
        "# 初回近傍ベクトル\n",
        "near_vector_array = []\n",
        "\n",
        "near_vector_array.append(candidate_vector.copy())\n",
        "for key in candidate_vector:\n",
        "    if not key in fixed_variable:\n",
        "        near_vector = candidate_vector.copy()\n",
        "        near_vector[key] = (near_vector[key] + 1) % len(value_space[key])\n",
        "        near_vector_array.append(near_vector)\n",
        "\n",
        "        near_vector = candidate_vector.copy()\n",
        "        near_vector[key] = (near_vector[key] - 1) % len(value_space[key])\n",
        "        near_vector_array.append(near_vector)\n",
        "\n",
        "\"\"\"\n",
        "near_vector_array.append({'CNN_conv2d_filters': 3, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 0, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 1, 'CNN_drop_ratio': 10, 'width': 5, 'height': 5, 'batch_size': 2, 'color_mode': 1, 'rotation_range': 0, 'width_shift_range': 0, 'height_shift_range': 0, 'zoom_range': 0, 'brightness_range': 0, 'fill_mode': 0})\n",
        "near_vector_array.append({'CNN_conv2d_filters': 3, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 0, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 1, 'CNN_drop_ratio': 10, 'width': 5, 'height': 5, 'batch_size': 2, 'color_mode': 1, 'rotation_range': 0, 'width_shift_range': 0, 'height_shift_range': 0, 'zoom_range': 0, 'brightness_range': 0, 'fill_mode': 0})\n",
        "random.shuffle(near_vector_array)\n",
        "\"\"\"\n",
        "# 最良近傍ベクトルを現在位置で初期化\n",
        "candidate_vector[\"evaluation_value\"] = 1.0\n",
        "best_near_vector = candidate_vector.copy()\n",
        "\n",
        "# %% [markdown]\n",
        "# ----\n",
        "# # # # # # # # 近傍解ループ　ここから\n",
        "\n",
        "# %% [code]\n",
        "CNN_model = None\n",
        "while(True):\n",
        "    print(\"####################################################################################################\")\n",
        "    for near_vector in near_vector_array:\n",
        "        print(near_vector)\n",
        "            \n",
        "    for near_vector in near_vector_array:\n",
        "        print(\"--------------------------------------------------------------------------------------------------\")\n",
        "        print(near_vector)\n",
        "\n",
        "        # %% [markdown]\n",
        "        # ----\n",
        "        # Create model\n",
        "\n",
        "        # %% [code]\n",
        "        # optimizerの初期化\n",
        "        #optimizer = Adam(lr=0.0001)\n",
        "        #optimizer = RMSprop(lr=2e-5) #, decay=1e-3)\n",
        "        #optimizer = SGD(lr=2e-5, momentum=0.9, decay=1e-6, nesterov=True)\n",
        "        optimizer = SGD(lr=1e-4, momentum=0.9)\n",
        "        \n",
        "        # モデルの定義\n",
        "        if value_space[\"color_mode\"][near_vector[\"color_mode\"]] == \"grayscale\":\n",
        "            num_color = 1\n",
        "        else:\n",
        "            num_color = 3\n",
        "        try:\n",
        "            CNN_model = CNN(input_shape=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],num_color),\n",
        "                            kernel_size=(value_space[\"CNN_kernel_size\"][near_vector[\"CNN_kernel_size\"]],value_space[\"CNN_kernel_size\"][near_vector[\"CNN_kernel_size\"]]),\n",
        "                            max_pooling_size=(value_space[\"CNN_max_pooling_size\"][near_vector[\"CNN_max_pooling_size\"]],value_space[\"CNN_max_pooling_size\"][near_vector[\"CNN_max_pooling_size\"]]),\n",
        "                            act_func=value_space[\"CNN_act_func\"][near_vector[\"CNN_act_func\"]],\n",
        "                            drop_ratio=value_space[\"CNN_drop_ratio\"][near_vector[\"CNN_drop_ratio\"]],\n",
        "                            num_layer=value_space[\"CNN_num_layer\"][near_vector[\"CNN_num_layer\"]],\n",
        "                            conv2d_filters=value_space[\"CNN_conv2d_filters\"][near_vector[\"CNN_conv2d_filters\"]],\n",
        "                            num_dence_layer=value_space[\"CNN_num_dence_layer\"][near_vector[\"CNN_num_dence_layer\"]],\n",
        "                            num_conv2d_layer=value_space[\"CNN_num_conv2d_layer\"][near_vector[\"CNN_num_conv2d_layer\"]],\n",
        "                           )\n",
        "        except Exception as e:\n",
        "            print(\"Skipped as ValueError was raised at CNN().\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "        \n",
        "        # モデルのコンパイル\n",
        "        CNN_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # モデル情報を表示\n",
        "        CNN_model.summary()\n",
        "        \n",
        "        if not NUM_EPOCH == 0:\n",
        "            # %% [code]\n",
        "            # 画像ファイル名, label情報の取得\n",
        "            train_df = pd.read_csv(train_labels_path, dtype='str')\n",
        "    #        display(train_df.head())\n",
        "            train_preprocessed_dir = train_pre_dir\n",
        "            os.makedirs(train_preprocessed_dir, exist_ok=True)\n",
        "            for path in tqdm(train_df['filename']):\n",
        "                img = Image.open(train_dir + path)\n",
        "                img = img.resize((value_space[\"width_x_height\"][near_vector[\"width_x_height\"]], value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]))\n",
        "                img.save(train_preprocessed_dir + path)\n",
        "\n",
        "            # %% [code]\n",
        "            #-----------------------------------------------#\n",
        "            # ImageDataGenerator\n",
        "            #   - 画像の読み込み & 水増し(Data Augmentation)\n",
        "            #   - 学習時にリアルタイムにファイルからデータ読み込み\n",
        "            #     →Data Augmentationを行う\n",
        "            #   - Augmentationをリアルタイムに行うのでメモリを圧迫しない\n",
        "            #   - どのような変換をするかはインスタンス生成時に指定する\n",
        "            #-----------------------------------------------#\n",
        "\n",
        "            # trainデータ用インスタンス生成\n",
        "            train_datagen = ImageDataGenerator(\n",
        "                rescale=1. / 255,              # 画像の正規化\n",
        "    #            rotation_range=value_space[\"rotation_range\"][near_vector[\"rotation_range\"]],             # ランダムに画像を回転 (単位：度)\n",
        "    #            width_shift_range=value_space[\"width_shift_range\"][near_vector[\"width_shift_range\"]],        # ランダムに画像を水平シフト (画像横幅に対する割合を指定)\n",
        "    #            height_shift_range=value_space[\"height_shift_range\"][near_vector[\"height_shift_range\"]],       # ランダムに画像を垂直シフト (画像縦幅に対する割合を指定)\n",
        "    #            zoom_range=[1.0-value_space[\"zoom_range\"][near_vector[\"zoom_range\"]], 1.0+value_space[\"zoom_range\"][near_vector[\"zoom_range\"]]],        # ランダムに画像を拡縮 (下限, 上限)\n",
        "    #            horizontal_flip=True,         # ランダムに画像を左右反転\n",
        "    #            vertical_flip=False,           # ランダムに画像を上下反転\n",
        "    #            brightness_range=[1.0-value_space[\"brightness_range\"][near_vector[\"brightness_range\"]], 1.0+value_space[\"brightness_range\"][near_vector[\"brightness_range\"]]],  # ランダムに画像を輝度変換 (下限, 上限)\n",
        "    #            fill_mode=value_space[\"fill_mode\"][near_vector[\"fill_mode\"]],          # 画像変換時に生じた空白部分の埋め方 (nearestは近傍値で埋める)\n",
        "                validation_split = 0.3         # validationデータの割合\n",
        "                )\n",
        "\n",
        "            # %% [markdown]\n",
        "            # 参考リンク\n",
        "            # # - [ImageDataGenerator｜Keras公式ドキュメント](https://keras.io/ja/preprocessing/image/)  \n",
        "            # # - [Kerasによるデータ拡張｜人工知能に関する断創録](http://aidiary.hatenablog.com/entry/20161212/1481549365)\n",
        "\n",
        "            # %% [code]\n",
        "            #-----------------------------------------------#\n",
        "            # ImageDataGenerator.flow_from_dataframe\n",
        "            #   - DataFrameからデータ生成用ジェネレーター作成\n",
        "            #\n",
        "            #     dataframe  : 読み込むDataFrame\n",
        "            #     directory  : 元画像が格納されているディレクトリ名\n",
        "            #     x_col      : 画像名を表すcolumn\n",
        "            #     y_col      : ラベルを表すcolumn\n",
        "            #     target_size: 指定した画像サイズにリサイズする\n",
        "            #     batch_size : 学習時のミニバッチサイズ\n",
        "            #     class_mode : 問題設定  'binary'=二値分類\n",
        "            #     shuffle    : 画像読み込み順をシャッフルする\n",
        "            #     seed       : 乱数シード値\n",
        "            #     subset     : trainデータかvalidデータかを指定\n",
        "            #-----------------------------------------------#\n",
        "\n",
        "            # trainデータ用ジェネレーター\n",
        "            train_generator = train_datagen.flow_from_dataframe(\n",
        "                        dataframe=train_df,\n",
        "                        directory=train_preprocessed_dir,\n",
        "                        x_col='filename',\n",
        "                        y_col='label',\n",
        "                        target_size=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]),\n",
        "                        batch_size=value_space[\"batch_size\"][near_vector[\"batch_size\"]],\n",
        "                        color_mode=value_space[\"color_mode\"][near_vector[\"color_mode\"]],\n",
        "                        class_mode='binary',\n",
        "                        shuffle=True,\n",
        "                        seed=1111,\n",
        "                        subset = \"training\"\n",
        "                    )\n",
        "\n",
        "            # validデータ用ジェネレーター\n",
        "            val_generator = train_datagen.flow_from_dataframe(\n",
        "                        dataframe=train_df,\n",
        "                        directory=train_preprocessed_dir,\n",
        "                        x_col='filename',\n",
        "                        y_col='label',\n",
        "                        target_size=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]),\n",
        "                        batch_size=value_space[\"batch_size\"][near_vector[\"batch_size\"]],\n",
        "                        color_mode=value_space[\"color_mode\"][near_vector[\"color_mode\"]],\n",
        "                        class_mode='binary',\n",
        "                        shuffle=True,\n",
        "                        seed=1111,\n",
        "                        subset = \"validation\"\n",
        "                    )\n",
        "\n",
        "            # %% [code]\n",
        "            # 各Epoch終了時に呼び出すcallback\n",
        "            callbacks = []\n",
        "\n",
        "            # 学習ログをCSVに書き出す\n",
        "            callbacks.append(CSVLogger('history.csv'))\n",
        "\n",
        "            # --過学習防止用callback--\n",
        "            # patienceで指定したEpochの間, monitorの値が改善しなければ学習を打ち切る\n",
        "            #callbacks.append(EarlyStopping(patience=8, monitor='val_acc'))\n",
        "\n",
        "            # --学習率スケジューリング用callback--\n",
        "            # patienceで指定したEpochの間, monitorの値が改善しなければ\n",
        "            # 現在の学習率にfactorをかけて学習を継続する\n",
        "            callbacks.append(ReduceLROnPlateau(patience=3, monitor='val_acc',\n",
        "                                              factor=0.5, min_lr=1e-5, verbose=1))\n",
        "\n",
        "            # --エポックごとに経過保存callback--\n",
        "            os.makedirs(model_check_point_dir, exist_ok=True)\n",
        "            callbacks.append(ModelCheckpoint(filepath = os.path.join(model_check_point_dir,'cnn_model-epoch{epoch:02d}-loss{loss:.4f}-acc{acc:.4f}-vloss{val_loss:.4f}-vacc{val_acc:.4f}.hdf5'), monitor='val_loss', verbose=1, save_best_only=False, mode='auto'))\n",
        "\n",
        "        # 重みロード\n",
        "        weight_path = '/content/drive/My Drive/dogcat/model/cnn_model-epoch09-loss0.0208-acc0.9939-vloss0.0148-vacc0.9953.hdf5'\n",
        "        CNN_model.load_weights(weight_path)\n",
        "        print('Using weight file : ' + weight_path)\n",
        "\n",
        "        if NUM_EPOCH == 0:\n",
        "            print('break without fit (NUM_EPOCH == 0)')\n",
        "            break\n",
        "\n",
        "        # %% [code]\n",
        "        # 学習の実施\n",
        "        try:\n",
        "            history = CNN_model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=len(train_generator),\n",
        "                epochs=NUM_EPOCH,\n",
        "                validation_data=val_generator,\n",
        "                validation_steps=len(val_generator),\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"Skipped as ValueError was raised at CNN_model.fit_generator()\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "        # 学習結果の表示\n",
        "        show_fit_result(history)\n",
        "\n",
        "        # 現在の解ベクトル評価\n",
        "\n",
        "        # 検証データのLogLoss平均を取得して評価値とする\n",
        "        loss, acc = CNN_model.evaluate_generator(val_generator, steps=len(val_generator), verbose=1)\n",
        "        print('Test loss: %s, Test acc: %s' % (loss, acc))\n",
        "        near_vector[\"evaluation_value\"] = loss\n",
        "\n",
        "        # LogLoss平均\n",
        "        #print(loglossavg(train_df['label'].as_matrix(),preds))\n",
        "\n",
        "        # 最良の近傍解と比較\n",
        "        if near_vector[\"evaluation_value\"] < best_near_vector[\"evaluation_value\"]:\n",
        "            best_near_vector = near_vector.copy()\n",
        "\n",
        "        print(\"Best near vector=\")\n",
        "        print(best_near_vector)\n",
        "        print(\"Candidate vector=\")\n",
        "        print(candidate_vector)\n",
        "        \n",
        "        \n",
        "    # 現在のベクトルより良い近傍ベクトルがあれば移動し、なければ終了\n",
        "    if best_near_vector[\"evaluation_value\"] < candidate_vector[\"evaluation_value\"]:\n",
        "        print(\"Better vector found.\")\n",
        "        # 移動先の近傍ベクトルのリストを生成\n",
        "        near_vector_array = []\n",
        "        for key in best_near_vector:\n",
        "            if key == \"evaluation_value\":\n",
        "                    continue\n",
        "            if not key in fixed_variable:\n",
        "                near_vector = best_near_vector.copy()\n",
        "                near_vector[key] = (near_vector[key] + 1) % len(value_space[key])\n",
        "                near_vector_array.append(near_vector)\n",
        "\n",
        "                near_vector = best_near_vector.copy()\n",
        "                near_vector[key] = (near_vector[key] - 1) % len(value_space[key])\n",
        "                near_vector_array.append(near_vector)\n",
        "\n",
        "        # 前回の解候補を除外\n",
        "        index = 0\n",
        "        for near_vector in near_vector_array:\n",
        "            if near_vector == candidate_vector:\n",
        "                near_vector_array.remove(index)\n",
        "                break\n",
        "            index += 1\n",
        "        \n",
        "        # 移動\n",
        "        candidate_vector = best_near_vector.copy()\n",
        "        \n",
        "        \n",
        "    else:\n",
        "        # 最適化終了\n",
        "        break\n",
        "\n",
        "# %% [markdown]\n",
        "# # 近傍解ループここまで\n",
        "# # # # # # # ----\n",
        "\n",
        "# %% [code]\n",
        "#最適ベクトルで100エポックで再学習"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using file path for Google Colaboratory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "####################################################################################################\n",
            "{'CNN_conv2d_filters': 5, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 4, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 0, 'CNN_drop_ratio': 0, 'CNN_num_conv2d_layer': 0, 'width_x_height': 5, 'batch_size': 0, 'color_mode': 1, 'rotation_range': 10, 'width_shift_range': 2, 'height_shift_range': 2, 'zoom_range': 0, 'brightness_range': 5, 'fill_mode': 0}\n",
            "--------------------------------------------------------------------------------------------------\n",
            "{'CNN_conv2d_filters': 5, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 4, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 0, 'CNN_drop_ratio': 0, 'CNN_num_conv2d_layer': 0, 'width_x_height': 5, 'batch_size': 0, 'color_mode': 1, 'rotation_range': 10, 'width_shift_range': 2, 'height_shift_range': 2, 'zoom_range': 0, 'brightness_range': 5, 'fill_mode': 0}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Model)  (None, 1536)              54336736  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               393472    \n",
            "_________________________________________________________________\n",
            "batch_normalization_204 (Bat (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_204 (Activation)  (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 54,731,489\n",
            "Trainable params: 54,670,433\n",
            "Non-trainable params: 61,056\n",
            "_________________________________________________________________\n",
            "Using weight file : /content/drive/My Drive/dogcat/model/cnn_model-epoch09-loss0.0208-acc0.9939-vloss0.0148-vacc0.9953.hdf5\n",
            "break without fit (NUM_EPOCH == 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP-BFVjAoxD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be1c8424-8d7b-4edb-c26e-5fdc272660ce"
      },
      "source": [
        "#テストデータ予測＆submissionファイル作成\n",
        "print('Creating submission.csv...')\n",
        "\n",
        "# testデータ読み込み\n",
        "test_df = pd.read_csv(sample_submission_path, dtype='str')\n",
        "#display(test_df.head())\n",
        "test_preprocessed_dir = test_pre_dir\n",
        "os.makedirs(test_preprocessed_dir, exist_ok=True)\n",
        "\n",
        "# testデータ前処理\n",
        "for path in tqdm(test_df['filename']):\n",
        "    img = Image.open(test_dir + path)\n",
        "\n",
        "    # 正方形になるように余白追加\n",
        "    width, height = img.size\n",
        "    if height == width:\n",
        "        #print('height == width')\n",
        "        pass\n",
        "    elif height > width:\n",
        "        #print('height > width')\n",
        "        img = img.crop((-(height-width)/2, 0, width+(height-width)/2, height))\n",
        "    else:\n",
        "        #print('height < width')\n",
        "        img = img.crop((0, -((width-height)/2), width, height+(width-height)/2))\n",
        "\n",
        "    img = img.resize((value_space[\"width_x_height\"][near_vector[\"width_x_height\"]], value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]))\n",
        "    img.save(test_preprocessed_dir + path)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_preprocessed_dir,\n",
        "            x_col='filename',\n",
        "            y_col=None,\n",
        "            target_size=(value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]],value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]]),\n",
        "            batch_size=value_space[\"batch_size\"][candidate_vector[\"batch_size\"]],\n",
        "            color_mode=value_space[\"color_mode\"][candidate_vector[\"color_mode\"]],\n",
        "            class_mode=None,\n",
        "            shuffle=False,\n",
        "            seed=1111\n",
        "        )\n",
        "\n",
        "# テストデータ予測\n",
        "preds = CNN_model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(len(test_generator))\n",
        "\n",
        "# testデータ予測結果の表示\n",
        "sns.distplot(np.reshape(preds, (-1,)))\n",
        "\n",
        "# submissionファイルの生成\n",
        "submission = pd.read_csv(sample_submission_path)\n",
        "submission['label'] = np.reshape(preds, (-1,))\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(submission)\n",
        "#submission.head()\n",
        "\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission)\n",
        "\n",
        "# %% [code]\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission)\n",
        "\n",
        "# %% [code]\n",
        "import shutil\n",
        "#shutil.rmtree(train_preprocessed_dir)\n",
        "#shutil.rmtree(test_preprocessed_dir)# %% [markdown]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating submission.csv...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4bef5a341cb4b168b5f195cf44cd11f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=8000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Found 8000 validated image filenames.\n",
            "1000/1000 [==============================] - 677s 677ms/step\n",
            "1000\n",
            "      filename     label\n",
            "0        1.jpg  0.999579\n",
            "1        2.jpg  0.000208\n",
            "2        3.jpg  0.001019\n",
            "3        4.jpg  0.999716\n",
            "4        5.jpg  0.000006\n",
            "5        6.jpg  0.000133\n",
            "6        7.jpg  0.000404\n",
            "7        8.jpg  0.999354\n",
            "8        9.jpg  0.999540\n",
            "9       10.jpg  0.999379\n",
            "10      11.jpg  0.998469\n",
            "11      12.jpg  0.000092\n",
            "12      13.jpg  0.999640\n",
            "13      14.jpg  0.999724\n",
            "14      15.jpg  0.000869\n",
            "15      16.jpg  0.999571\n",
            "16      17.jpg  0.999437\n",
            "17      18.jpg  0.999223\n",
            "18      19.jpg  0.000048\n",
            "19      20.jpg  0.000613\n",
            "20      21.jpg  0.001242\n",
            "21      22.jpg  0.000005\n",
            "22      23.jpg  0.998611\n",
            "23      24.jpg  0.999379\n",
            "24      25.jpg  0.999392\n",
            "25      26.jpg  0.000043\n",
            "26      27.jpg  0.999790\n",
            "27      28.jpg  0.000028\n",
            "28      29.jpg  0.000009\n",
            "29      30.jpg  0.000713\n",
            "...        ...       ...\n",
            "7970  7971.jpg  0.998536\n",
            "7971  7972.jpg  0.998927\n",
            "7972  7973.jpg  0.000196\n",
            "7973  7974.jpg  0.000476\n",
            "7974  7975.jpg  0.997365\n",
            "7975  7976.jpg  0.999135\n",
            "7976  7977.jpg  0.000035\n",
            "7977  7978.jpg  0.998471\n",
            "7978  7979.jpg  0.999589\n",
            "7979  7980.jpg  0.000173\n",
            "7980  7981.jpg  0.999201\n",
            "7981  7982.jpg  0.000068\n",
            "7982  7983.jpg  0.000114\n",
            "7983  7984.jpg  0.996998\n",
            "7984  7985.jpg  0.999619\n",
            "7985  7986.jpg  0.000003\n",
            "7986  7987.jpg  0.000059\n",
            "7987  7988.jpg  0.000021\n",
            "7988  7989.jpg  0.999596\n",
            "7989  7990.jpg  0.000066\n",
            "7990  7991.jpg  0.000167\n",
            "7991  7992.jpg  0.000028\n",
            "7992  7993.jpg  0.999209\n",
            "7993  7994.jpg  0.998195\n",
            "7994  7995.jpg  0.001774\n",
            "7995  7996.jpg  0.999121\n",
            "7996  7997.jpg  0.000342\n",
            "7997  7998.jpg  0.000023\n",
            "7998  7999.jpg  0.999119\n",
            "7999  8000.jpg  0.318372\n",
            "\n",
            "[8000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDGxUIv2Q7az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binning & 確信度が低いファイル名表示\n",
        "import csv\n",
        "\n",
        "outary = []\n",
        "with open('submission.csv', 'r') as fin:\n",
        "  reader = csv.reader(fin)\n",
        "  header = next(reader)\n",
        "  outary.append(header)\n",
        "\n",
        "  b0 = 0\n",
        "  b1 = 0\n",
        "  b2 = 0\n",
        "  for row in reader:\n",
        "    if float(row[1]) > 0.01 and float(row[1]) < 0.99 :\n",
        "      b0 += 1\n",
        "      print(str(b0), ' : ', row)\n",
        "      row[1] = 0.5\n",
        "    elif float(row[1]) <= 0.01:\n",
        "      row[1] = 0.0001 # 0にして間違うとLogLoss無限になる\n",
        "    else:\n",
        "      row[1] = 0.9999 # 1にして間違うとLogLoss無限になる\n",
        "#   print(row[1])\n",
        "    outary.append(row)\t\n",
        "\n",
        "with open('submission_step.csv', 'w') as fout:\n",
        "    writer = csv.writer(fout, lineterminator='\\n')\n",
        "    writer.writerows(outary)\n",
        "fout.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fN3cmcg3x3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grad-CAM++による判断根拠可視化\n",
        "# CNNの最終畳み込み層を指定する必要あり\n",
        "# 事前にCNN_modelに学習済みCNNモデルを入れておく\n",
        "# 以下は活性化関数が２階微分で０になることが前提\n",
        "# https://qiita.com/Dason08/items/a8013b3fa4d303f5c41c\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import argparse\n",
        "import keras\n",
        "import time\n",
        "import sys\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "def Grad_Cam_plus_plus(input_model, layer_name, x, row, col):\n",
        "    '''\n",
        "    Args:\n",
        "       input_model: ResNet50のモデル\n",
        "       x: 画像(array)\n",
        "       layer_name: 畳み込み層の名前\n",
        "       (row, col): 画像のサイズ\n",
        "    Returns:\n",
        "       jetcam: 影響の大きい箇所を色付けした画像(array)\n",
        "    '''\n",
        "\n",
        "    model = input_model\n",
        "\n",
        "    #前処理\n",
        "    X = np.expand_dims(x, axis=0)\n",
        "    X = X.astype('float32')\n",
        "    preprocessed_input = X / 255.0\n",
        "\n",
        "\n",
        "    #予測クラスの算出\n",
        "    predictions = model.predict(preprocessed_input)\n",
        "    class_idx = np.argmax(predictions[0])\n",
        "\n",
        "    #使用する重みの抽出、高階微分の計算\n",
        "    class_output = model.layers[-1].output\n",
        "    conv_output = model.get_layer(layer_name).get_output_at(1) # ImageNetのInceptionResNetV2の場合は1\n",
        "    grads = K.gradients(class_output, conv_output)[0]\n",
        "    #first_derivative：１階微分\n",
        "    first_derivative = K.exp(class_output)[0][class_idx] * grads\n",
        "    #second_derivative：２階微分\n",
        "    second_derivative = K.exp(class_output)[0][class_idx] * grads * grads\n",
        "    #third_derivative：３階微分\n",
        "    third_derivative = K.exp(class_output)[0][class_idx] * grads * grads * grads\n",
        "\n",
        "    #関数の定義\n",
        "    gradient_function = K.function([model.input], [conv_output, first_derivative, second_derivative, third_derivative])  # model.inputを入力すると、conv_outputとgradsを出力する関数\n",
        "\n",
        "\n",
        "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = gradient_function([preprocessed_input])\n",
        "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = conv_output[0], conv_first_grad[0], conv_second_grad[0], conv_third_grad[0]\n",
        "\n",
        "    #alphaを求める\n",
        "    global_sum = np.sum(conv_output.reshape((-1, conv_first_grad.shape[2])), axis=0)\n",
        "    alpha_num = conv_second_grad\n",
        "    alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((1,1,conv_first_grad.shape[2]))\n",
        "    alpha_denom = np.where(alpha_denom!=0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
        "    alphas = alpha_num / alpha_denom\n",
        "\n",
        "    #alphaの正規化\n",
        "    alpha_normalization_constant = np.sum(np.sum(alphas, axis = 0), axis = 0)\n",
        "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
        "    alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad.shape[2]))\n",
        "\n",
        "    #wの計算\n",
        "    weights = np.maximum(conv_first_grad, 0.0)\n",
        "    deep_linearization_weights = np.sum((weights * alphas).reshape((-1, conv_first_grad.shape[2])))\n",
        "\n",
        "    #Lの計算\n",
        "    grad_CAM_map = np.sum(deep_linearization_weights * conv_output, axis=2)\n",
        "    grad_CAM_map = np.maximum(grad_CAM_map, 0)\n",
        "    grad_CAM_map = grad_CAM_map / np.max(grad_CAM_map)\n",
        "\n",
        "    #ヒートマップを描く\n",
        "    grad_CAM_map = cv2.resize(grad_CAM_map, (row, col), cv2.INTER_LINEAR)\n",
        "    jetcam = cv2.applyColorMap(np.uint8(255 * grad_CAM_map), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
        "    jetcam = (np.float32(jetcam) + x / 2)   # もとの画像に合成\n",
        "\n",
        "    return jetcam\n",
        "\n",
        "#image_path = test_pre_dir + '493.jpg' # Target image file path\n",
        "#image_path = './train/cat.4289.jpg'\n",
        "image_path = './crop.jpg'\n",
        "#image_path = './drive/My Drive/dogcat/input/20190614182430.JPG'\n",
        "\n",
        "target_layer = 'inception_resnet_v2' # InceptionResNetV2\n",
        "row = value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]\n",
        "col = value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]\n",
        "\n",
        "img = img_to_array(load_img(image_path,target_size=(row,col)))\n",
        "img_GCAMplusplus = Grad_Cam_plus_plus(CNN_model, target_layer, img, row, col)\n",
        "time = time.ctime()\n",
        "img_Gplusplusname = gradcam_dir +os.path.basename(image_path) + \"_GCAM++.jpg\"\n",
        "os.makedirs(gradcam_dir, exist_ok=True)\n",
        "cv2.imwrite(img_Gplusplusname, img_GCAMplusplus)\n",
        "\n",
        "def hconcat_resize_min(im_list, interpolation=cv2.INTER_CUBIC):\n",
        "    h_min = min(im.shape[0] for im in im_list)\n",
        "    im_list_resize = [cv2.resize(im, (int(im.shape[1] * h_min / im.shape[0]), h_min), interpolation=interpolation)\n",
        "                      for im in im_list]\n",
        "    return cv2.hconcat(im_list_resize)\n",
        "\n",
        "original_image = cv2.cvtColor(cv2.resize(cv2.imread(image_path), (row,col)), cv2.COLOR_BGR2RGB)\n",
        "gradcam_image = cv2.cvtColor(cv2.imread(img_Gplusplusname), cv2.COLOR_BGR2RGB)\n",
        "im_h_resize = hconcat_resize_min([original_image, gradcam_image])\n",
        "plt.imshow(im_h_resize)\n",
        "print('Heat Map')\n",
        "\n",
        "# 予測\n",
        "img_predict = []\n",
        "try:\n",
        "    img = Image.open(image_path)  # 画像読み込み\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((row, col))  # 画像のリサイズ\n",
        "    img_array = np.asarray(img)\n",
        "    img_predict.append(img_array)\n",
        "except Exception as e:\n",
        "    pass\n",
        "img_predict = np.asarray(img_predict) / 255.\n",
        "result_predict = CNN_model.predict(img_predict)\n",
        "print('prob = ', result_predict[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAnb58EqNtN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 転移学習の場合は以下を実行して最後の方の畳み込み層を見つける\n",
        "print(CNN_model.get_layer('inception_resnet_v2').get_output_at(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5gZsc_yUf1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデル保存\n",
        "CNN_model.save('drive/My Drive/dogcat/model/cnn_model-')\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mZd7XKimos2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 二つの結果ファイルをマージ\n",
        "submission1_path = 'submission (1).csv'\n",
        "submission2_path = 'submission_original.csv'\n",
        "\n",
        "import csv\n",
        "\n",
        "outary = []\n",
        "\n",
        "data_array = []\n",
        "data = []\n",
        "\n",
        "with open(submission1_path, 'r') as fin:\n",
        "\t  reader = csv.reader(fin)\n",
        "\t  header = next(reader)\n",
        "\t  outary.append(header)\n",
        "\t  for row in reader:\n",
        "\t\t    data.append(row)\n",
        "\n",
        "data_array.append(data)\n",
        "data = []\n",
        "\n",
        "with open(submission2_path, 'r') as fin:\n",
        "    reader = csv.reader(fin)\n",
        "    header = next(reader)\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "data_array.append(data)\n",
        "\n",
        "'''\n",
        "for irow in range(len(data)):\n",
        "    max_conf = 0.\n",
        "    max_data_row = None\n",
        "    for temp_data in data_array:\n",
        "        if abs(float(temp_data[irow][1]) - 0.5) >= max_conf:\n",
        "            max_conf = abs(float(temp_data[irow][1]) - 0.5)\n",
        "            max_data_row = temp_data[irow]\n",
        "    outary.append(max_data_row)\n",
        "'''\n",
        "\n",
        "count = 0\n",
        "data_priority = 0\n",
        "for irow in range(len(data)):\n",
        "    row = data_array[data_priority][irow]\n",
        "    if float(row[1]) > 0.01 and float(row[1]) < 0.99 :\n",
        "      count += 1\n",
        "      print(str(count), ' : ', row)\n",
        "      row[1] = (float(row[1]) + float(data_array[data_priority+1][irow][1]))/2\n",
        "      print(str(count), ' : ', row)\n",
        "    outary.append(row)\n",
        "\n",
        "with open('submission_merge.csv', 'w') as fout:\n",
        "    writer = csv.writer(fout, lineterminator='\\n')\n",
        "    writer.writerows(outary)\n",
        "fout.close()\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDDrrjBaHe2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "058264db-3fad-4381-951c-76354c7a1b8c"
      },
      "source": [
        "#本家テストデータ予測＆submissionファイル作成\n",
        "print('Creating submission_original.csv...')\n",
        "\n",
        "# 本家testデータ読み込み\n",
        "test_original_df = pd.read_csv(sample_submission_original_path, dtype='str')\n",
        "#display(test_df.head())\n",
        "test_original_preprocessed_dir = test_original_pre_dir\n",
        "os.makedirs(test_original_preprocessed_dir, exist_ok=True)\n",
        "\n",
        "# 本家testデータ前処理\n",
        "for path in tqdm(test_original_df['filename']):\n",
        "    img = Image.open(test_original_dir + path)\n",
        "\n",
        "    # 正方形になるように余白追加\n",
        "    width, height = img.size\n",
        "    if height == width:\n",
        "        #print('height == width')\n",
        "        pass\n",
        "    elif height > width:\n",
        "        #print('height > width')\n",
        "        img = img.crop((-(height-width)/2, 0, width+(height-width)/2, height))\n",
        "    else:\n",
        "        #print('height < width')\n",
        "        img = img.crop((0, -((width-height)/2), width, height+(width-height)/2))\n",
        "\n",
        "    img = img.resize((value_space[\"width_x_height\"][near_vector[\"width_x_height\"]], value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]))\n",
        "    img.save(test_original_preprocessed_dir + path)\n",
        "\n",
        "test_original_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_original_generator = test_original_datagen.flow_from_dataframe(\n",
        "            dataframe=test_original_df,\n",
        "            directory=test_original_preprocessed_dir,\n",
        "            x_col='filename',\n",
        "            y_col=None,\n",
        "            target_size=(value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]],value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]]),\n",
        "            batch_size=value_space[\"batch_size\"][candidate_vector[\"batch_size\"]],\n",
        "            color_mode=value_space[\"color_mode\"][candidate_vector[\"color_mode\"]],\n",
        "            class_mode=None,\n",
        "            shuffle=False,\n",
        "            seed=1111\n",
        "        )\n",
        "\n",
        "# 本家テストデータ予測\n",
        "preds = CNN_model.predict_generator(test_original_generator, steps=len(test_original_generator), verbose=1)\n",
        "print(len(test_original_generator))\n",
        "\n",
        "# 本家testデータ予測結果の表示\n",
        "sns.distplot(np.reshape(preds, (-1,)))\n",
        "\n",
        "# submissionファイルの生成\n",
        "submission_original = pd.read_csv(sample_submission_original_path)\n",
        "submission_original['label'] = np.reshape(preds, (-1,))\n",
        "submission_original.to_csv('submission_original.csv', index=False)\n",
        "print(submission_original)\n",
        "#submission.head()\n",
        "\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission_original)\n",
        "\n",
        "# %% [code]\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission_original)\n",
        "\n",
        "# %% [code]\n",
        "import shutil\n",
        "#shutil.rmtree(train_preprocessed_dir)\n",
        "#shutil.rmtree(test_original_preprocessed_dir)# %% [markdown]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating submission_original.csv...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "295094b2a01043048a30ac224ad55358",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=12500), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Found 12500 validated image filenames.\n",
            "1563/1563 [==============================] - 1051s 673ms/step\n",
            "1563\n",
            "        filename     label\n",
            "0          1.jpg  0.999596\n",
            "1          2.jpg  0.999820\n",
            "2          3.jpg  0.999653\n",
            "3          4.jpg  0.999367\n",
            "4          5.jpg  0.000019\n",
            "5          6.jpg  0.000009\n",
            "6          7.jpg  0.000016\n",
            "7          8.jpg  0.000041\n",
            "8          9.jpg  0.000116\n",
            "9         10.jpg  0.000042\n",
            "10        11.jpg  0.001108\n",
            "11        12.jpg  0.999039\n",
            "12        13.jpg  0.000009\n",
            "13        14.jpg  0.000004\n",
            "14        15.jpg  0.000357\n",
            "15        16.jpg  0.000045\n",
            "16        17.jpg  0.995240\n",
            "17        18.jpg  0.999670\n",
            "18        19.jpg  0.000449\n",
            "19        20.jpg  0.000043\n",
            "20        21.jpg  0.999698\n",
            "21        22.jpg  0.000001\n",
            "22        23.jpg  0.999493\n",
            "23        24.jpg  0.999182\n",
            "24        25.jpg  0.000792\n",
            "25        26.jpg  0.998493\n",
            "26        27.jpg  0.999610\n",
            "27        28.jpg  0.000005\n",
            "28        29.jpg  0.006509\n",
            "29        30.jpg  0.999462\n",
            "...          ...       ...\n",
            "12470  12471.jpg  0.999576\n",
            "12471  12472.jpg  0.999041\n",
            "12472  12473.jpg  0.000331\n",
            "12473  12474.jpg  0.000012\n",
            "12474  12475.jpg  0.000545\n",
            "12475  12476.jpg  0.999357\n",
            "12476  12477.jpg  0.999048\n",
            "12477  12478.jpg  0.989473\n",
            "12478  12479.jpg  0.000199\n",
            "12479  12480.jpg  0.000132\n",
            "12480  12481.jpg  0.000287\n",
            "12481  12482.jpg  0.000046\n",
            "12482  12483.jpg  0.000007\n",
            "12483  12484.jpg  0.999584\n",
            "12484  12485.jpg  0.000049\n",
            "12485  12486.jpg  0.999628\n",
            "12486  12487.jpg  0.999377\n",
            "12487  12488.jpg  0.999133\n",
            "12488  12489.jpg  0.999696\n",
            "12489  12490.jpg  0.996968\n",
            "12490  12491.jpg  0.994526\n",
            "12491  12492.jpg  0.999357\n",
            "12492  12493.jpg  0.999563\n",
            "12493  12494.jpg  0.999567\n",
            "12494  12495.jpg  0.000534\n",
            "12495  12496.jpg  0.000029\n",
            "12496  12497.jpg  0.000079\n",
            "12497  12498.jpg  0.998841\n",
            "12498  12499.jpg  0.999010\n",
            "12499  12500.jpg  0.000152\n",
            "\n",
            "[12500 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niM+ouEVEfEbFLSLiM/8fXYcvsYHRQvcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNEvPtaDTkZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像読み込み\n",
        "img = Image.open(\"train/cat.4289.jpg\")\n",
        "width, height = img.size\n",
        "print(img.size)\n",
        "\n",
        "# img[top : bottom, left : right]\n",
        "# サンプル1の切り出し、保存\n",
        "img1 = None\n",
        "if height == width:\n",
        "    print('height == width')\n",
        "    img1 = img\n",
        "elif height > width:\n",
        "    print('height > width')\n",
        "    img1 = img.crop((-(height-width)/2, 0, width+(height-width)/2, height))\n",
        "else:\n",
        "    print('height < width')\n",
        "    img1 = img.crop((0, -((width-height)/2), width, height+(width-height)/2))\n",
        "img1.save(\"crop.jpg\")\n",
        "plt.imshow(np.array(img1))\n",
        "print(img1.size)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}