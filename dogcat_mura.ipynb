{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogcat_mura.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muraryu/dogcat/blob/master/dogcat_mura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlyuWq63uwTM",
        "colab_type": "text"
      },
      "source": [
        "Google Colabの場合のみ最初に実行する\n",
        "\n",
        "ここではGoogleドライブから必要なデータを持ってくる(直接アップロードでも良いが面倒。KaggleAPIキーも面倒。)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpPRPlu0xPeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b8847d4e-1cc4-4c0a-9ab7-083a10c1a1d1"
      },
      "source": [
        "# 事前にGoogleドライブに必要なデータを保存しておく\n",
        "# => train_label.csv, sample_submission.csv, train.zip, test.zip\n",
        "\n",
        "# Googleドライブのマウント\n",
        "# 実行後、標準出力のURLをクリックしてアクセス許可＆認証コードを取得し、’Enter your authorization code:’に入力する\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Googleドライブに保存しておいた重いデータのみローカルにコピー\n",
        "!cp \"drive/My Drive/dogcat/input/train.zip\" ./\n",
        "!cp \"drive/My Drive/dogcat/input/test.zip\" ./\n",
        "\n",
        "# 解凍\n",
        "# 標準出力を '> /dev/null' で捨てないとブラウザが固まるため注意する\n",
        "# 同様に解凍後のフォルダを左のファイルビューで展開しないこと(ファイルが多すぎて固まる)\n",
        "!mkdir ./train\n",
        "!mkdir ./test\n",
        "!unzip train.zip -d ./train > /dev/null\n",
        "!unzip test.zip -d ./test > /dev/null\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘./train’: File exists\n",
            "mkdir: cannot create directory ‘./test’: File exists\n",
            "replace ./train/dog.8140.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "replace ./test/4745.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9B-6y2p59zZ",
        "colab_type": "code",
        "outputId": "b56987e1-9da6-42e0-ea63-b523d7ea9826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# パス　実行環境ごとに書き換え\n",
        "train_dir = 'train/'\n",
        "test_dir = 'test/'\n",
        "train_pre_dir = 'train_pre/'\n",
        "test_pre_dir = 'test_pre/'\n",
        "train_labels_path = 'drive/My Drive/dogcat/input/train_label.csv'\n",
        "sample_submission_path = 'drive/My Drive/dogcat/input/sample_submission.csv'\n",
        "\n",
        "# Google Colaboratory環境であることを示すフラグ\n",
        "google_colab_flag = []\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpvMJ7fQut36",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofv8fEIltxB0",
        "colab_type": "text"
      },
      "source": [
        "ここからKaggle共通"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b43dpyJyxAUR",
        "colab_type": "code",
        "outputId": "f6fe9984-47a2-40f0-b4d4-eede1fc86532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# Google Colaboratory環境ではない場合、Kaggleのファイルパスを使用\n",
        "if 'google_colab_flag' in locals():\n",
        "    print('Using file path for Google Colaboratory.')\n",
        "else:\n",
        "    print('Using file path for Kaggle.')\n",
        "    train_dir = '../input/train/'\n",
        "    test_dir = '../input/test/'\n",
        "    train_labels_path = '../input/train_label.csv'\n",
        "    train_pre_dir = '../train_pre/'\n",
        "    sample_submission_path = '../input/sample_submission.csv'\n",
        "    test_pre_dir = '../test_pre/'\n",
        "\n",
        "# %% [markdown]\n",
        "# 事前に画像サイズを統一しておくことで学習時間を短縮します。 \n",
        "\n",
        "# %% [markdown]\n",
        "# ********# Dogs vs Cats Recognition: InClass\n",
        "# # # # # # # # これは [Dogs vs Cats Recognition: InClass](https://www.kaggle.com/c/dog-cat-recognition/overview)のBase kernelです。  \n",
        "# # # # # # # # PythonのDeep learning用フレームワーク keras を使用し、基本的なCNNモデルを構築します。  \n",
        "# # # # # # # # またkerasの ImageDataGenerator を使用し、画像の水増し (Data Augmentation) を行えるようにしているのがポイントです。\n",
        "\n",
        "# %% [markdown]\n",
        "# ----\n",
        "# # # # # # # # Import, Config, Utilities\n",
        "# # # # # # # # まず初めに下記を行います。\n",
        "# # # # # # # # - 必要なライブラリのImport\n",
        "# # # # # # # # - 各種Config (乱数seed設定, 学習パラメタ...etc)\n",
        "# # # # # # # # - Utility関数の定義\n",
        "\n",
        "# %% [code]\n",
        "# 必要なライブラリのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "from IPython.display import HTML\n",
        "import base64\n",
        "\n",
        "# 追加\n",
        "import math\n",
        "from keras.applications import *\n",
        "import traceback\n",
        "\n",
        "# %% [code]\n",
        "# 関数\n",
        "\n",
        "# 学習曲線の描画関数\n",
        "def show_fit_result(history):\n",
        "    plt.figure(figsize=(16,4))\n",
        "    \n",
        "    # plot accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['acc'], label='trn_acc', marker='.')\n",
        "    plt.plot(history.history['val_acc'], label='val_acc', marker='.')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "    \n",
        "    # plot loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='trn_loss', marker='.')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss', marker='.')\n",
        "    plt.title('Crossentropy')\n",
        "    plt.legend()\n",
        "\n",
        "def CNN(input_shape, kernel_size, max_pooling_size, act_func, conv2d_filters, drop_ratio, num_layer, num_dence_layer, num_conv2d_layer):\n",
        "    # input_shape      : 入力次元数 \n",
        "    # kernel_size      : 畳み込み層のフィルタサイズ\n",
        "    # max_pooling_size : Pooling層のフィルタサイズ\n",
        "    # act_func         : 中間層の活性化関数\n",
        "    # drop_ratio       : Dropoutの割合\n",
        "    \n",
        "    # kernel initializers\n",
        "    gl_init = glorot_uniform(1111)\n",
        "    \n",
        "    # Sequentialモデルのインスタンス作成\n",
        "    model = Sequential()\n",
        "\n",
        "    \"\"\"\n",
        "    for i in range(num_layer):\n",
        "        for j in range(num_conv2d_layer):\n",
        "            if i == 0 and j == 0:\n",
        "                model.add(Conv2D(conv2d_filters, kernel_size, activation='relu', input_shape=input_shape, kernel_initializer=gl_init))\n",
        "            else:\n",
        "                model.add(Conv2D(conv2d_filters, kernel_size, activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "        model.add(Dropout(drop_ratio, seed=1111))\n",
        "\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "        \n",
        "    for i in range(num_dence_layer):\n",
        "        model.add(Dense(int(1024/(2**i)), activation='relu', kernel_initializer=gl_init))\n",
        "    # 出力層\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    model.add(Conv2D(64, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init, input_shape=input_shape))\n",
        "    model.add(Conv2D(64, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(128, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(128, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(256, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(256, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(256, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(256, activation='relu', kernel_initializer=gl_init))\n",
        "    model.add(Dropout(0.5, seed=1111))\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "    \"\"\"\n",
        "    \n",
        "    #conv_base = Xception(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = VGG16(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = VGG19(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    conv_base = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = MobileNet(input_shape=input_shape, alpha=1.0, depth_multiplier=1, dropout=1e-3, include_top=False, weights='imagenet', pooling=None)\n",
        "    #conv_base = DenseNet201(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = NASNetLarge(input_shape=input_shape, include_top=False, weights='imagenet', pooling=None)\n",
        "    #conv_base = MobileNetV2(input_shape=input_shape, alpha=1.0, depth_multiplier=1, include_top=False, weights='imagenet', pooling=None)\n",
        "    \n",
        "    #conv_base.trainable = False\n",
        "    model.add(conv_base)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5, seed=1111))\n",
        "    model.add(Dense(1, activation='sigmoid')) \n",
        "\n",
        "    \n",
        "    \"\"\"\n",
        "    # 畳み込み層、Pooling層、Dropoutの追加\n",
        "    model.add(Conv2D(64, kernel_size, padding='same', activation=act_func, input_shape=input_shape, kernel_initializer=gl_init))\n",
        "    model.add(MaxPool2D(pool_size=max_pooling_size))\n",
        "    model.add(Dropout(drop_ratio, seed=1111))\n",
        "    \n",
        "    # 畳み込み層、Pooling層、Dropoutの追加\n",
        "    for i in range(num_layer):    \n",
        "        model.add(Conv2D(64, kernel_size, padding='same', activation=act_func, kernel_initializer=gl_init))\n",
        "        model.add(MaxPool2D(pool_size=max_pooling_size))\n",
        "        model.add(Dropout(drop_ratio, seed=1111))\n",
        "\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    # 全結合層の追加\n",
        "    model.add(Dense(128, activation=act_func, kernel_initializer=gl_init))\n",
        "    \n",
        "    # 出力層\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "    \"\"\"\n",
        "    \n",
        "    return model\n",
        "    \n",
        "def logloss(true_label, predicted, eps=1e-15):\n",
        "    p = np.clip(predicted, eps, 1 - eps)\n",
        "    true_label = int(true_label)\n",
        "    if true_label == 1:\n",
        "        return -math.log(p)\n",
        "    else:\n",
        "        return -math.log(1 - p)\n",
        "\n",
        "def loglossavg(true_label_ary, predicted_ary):\n",
        "    s = 0\n",
        "    i = 0\n",
        "    print(true_label_ary)\n",
        "    print(predicted_ary)\n",
        "    for true_label in true_label_ary:\n",
        "        s += logloss(true_label, predicted_ary[i])\n",
        "        i += 1\n",
        "    return s/i\n",
        "\n",
        "# (参考)下記関数を使うと、予測結果のCSVファイルをCommitなしで取得できます。\n",
        "# https://www.kaggle.com/rtatman/download-a-csv-file-from-a-kernel\n",
        "# function that takes in a dataframe and creates a text link to  \n",
        "# download it (will only work for files < 2MB or so)\n",
        "def create_download_link(df, title = \"Download CSV file\", filename = \"submission.csv\"):  \n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
        "    html = html.format(payload=payload,title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "\n",
        "### **注意**\n",
        "# # # # # # 上記で乱数seedを固定することで、ある程度は実験の再現性が得られますが、完全ではありません。  \n",
        "# # # # # # (kernel編集中の学習結果とCommit後の学習結果が微妙に異なる)  \n",
        "# # # # # # これはNVIDIA製GPUにおける並列計算処理が非決定的であるためです。  \n",
        "# # # # # # 本kernelの最後にはCommitなしで予測結果のCSVをダウンロードする方法も記載していますので参考にしてください。\n",
        "\n",
        "# 乱数seedの固定 (kerasの学習結果の再現性確保)\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(1111)\n",
        "random.seed(1111)\n",
        "\n",
        "session_conf = tf.ConfigProto(\n",
        "    intra_op_parallelism_threads=1,\n",
        "    inter_op_parallelism_threads=1\n",
        ")\n",
        "\n",
        "tf.set_random_seed(1111)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# %% [code]\n",
        "# 変数\n",
        "\n",
        "value_space = {}\n",
        "\n",
        "# CNNパラメータ\n",
        "value_space[\"CNN_conv2d_filters\"] = [4,8,16,32,64,128,192,256,512,1024,2048,4096,8192]\n",
        "value_space[\"CNN_num_dence_layer\"] = [0,1,2,3,4,5,6,7]\n",
        "value_space[\"CNN_num_layer\"] = np.arange(0, 11, 1)\n",
        "value_space[\"CNN_kernel_size\"] = np.arange(1, 11, 1)\n",
        "value_space[\"CNN_act_func\"] = [\"softmax\", \"elu\", \"selu\", \"softplus\", \"softsign\", \"relu\", \"tanh\", \"sigmoid\", \"hard_sigmoid\", \"linear\"]\n",
        "value_space[\"CNN_max_pooling_size\"] = np.arange(2, 11, 1)\n",
        "value_space[\"CNN_drop_ratio\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"CNN_num_conv2d_layer\"] = [1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# target size\n",
        "value_space[\"width_x_height\"] = [32,64,96,128,192,350,320,384,448,512]\n",
        "value_space[\"batch_size\"] = [16,32,48,128,256,512,1024,2048]\n",
        "value_space[\"color_mode\"] = [\"grayscale\", \"rgb\"]\n",
        "\n",
        "# 学習画像前処理\n",
        "value_space[\"rotation_range\"] = np.arange(0, 181, 5)\n",
        "value_space[\"width_shift_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"height_shift_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"zoom_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"brightness_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"fill_mode\"] = [\"nearest\", \"reflect\", \"wrap\"]\n",
        "\n",
        "# ベクトル初期化\n",
        "candidate_vector = {\n",
        "    \"CNN_conv2d_filters\":5,\n",
        "    \"CNN_num_dence_layer\":3,\n",
        "    \"CNN_num_layer\":4,\n",
        "    \"CNN_kernel_size\":2,\n",
        "    \"CNN_act_func\":5,\n",
        "    \"CNN_max_pooling_size\":0,\n",
        "    \"CNN_drop_ratio\":0,\n",
        "    \"CNN_num_conv2d_layer\":0,\n",
        "\n",
        "    \"width_x_height\":5,\n",
        "    \"batch_size\":0,\n",
        "    \"color_mode\":1,\n",
        "\n",
        "    \"rotation_range\":10,\n",
        "    \"width_shift_range\":2,\n",
        "    \"height_shift_range\":2,\n",
        "    \"zoom_range\":0,\n",
        "    \"brightness_range\":5,\n",
        "    \"fill_mode\":0,\n",
        "    }\n",
        "\n",
        "# 固定変数リスト\n",
        "fixed_variable = [\n",
        "    \"CNN_conv2d_filters\",\n",
        "    \"CNN_num_dence_layer\",\n",
        "    \"CNN_num_layer\",\n",
        "    \"CNN_kernel_size\",\n",
        "    \"CNN_act_func\",\n",
        "    \"CNN_max_pooling_size\",\n",
        "    \"CNN_drop_ratio\",\n",
        "    \"CNN_num_conv2d_layer\",\n",
        "\n",
        "    \"width_x_height\",\n",
        "    \"batch_size\",\n",
        "    \"color_mode\",\n",
        "\n",
        "    \"rotation_range\",\n",
        "    \"width_shift_range\",\n",
        "    \"height_shift_range\",\n",
        "    \"zoom_range\",\n",
        "    \"brightness_range\",\n",
        "    \"fill_mode\",\n",
        "]\n",
        "\n",
        "\n",
        "# number of epoch\n",
        "NUM_EPOCH = 30\n",
        "\n",
        "# %% [code]\n",
        "# 初回近傍ベクトル\n",
        "near_vector_array = []\n",
        "\n",
        "near_vector_array.append(candidate_vector.copy())\n",
        "for key in candidate_vector:\n",
        "    if not key in fixed_variable:\n",
        "        near_vector = candidate_vector.copy()\n",
        "        near_vector[key] = (near_vector[key] + 1) % len(value_space[key])\n",
        "        near_vector_array.append(near_vector)\n",
        "\n",
        "        near_vector = candidate_vector.copy()\n",
        "        near_vector[key] = (near_vector[key] - 1) % len(value_space[key])\n",
        "        near_vector_array.append(near_vector)\n",
        "\n",
        "\"\"\"\n",
        "near_vector_array.append({'CNN_conv2d_filters': 3, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 0, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 1, 'CNN_drop_ratio': 10, 'width': 5, 'height': 5, 'batch_size': 2, 'color_mode': 1, 'rotation_range': 0, 'width_shift_range': 0, 'height_shift_range': 0, 'zoom_range': 0, 'brightness_range': 0, 'fill_mode': 0})\n",
        "near_vector_array.append({'CNN_conv2d_filters': 3, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 0, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 1, 'CNN_drop_ratio': 10, 'width': 5, 'height': 5, 'batch_size': 2, 'color_mode': 1, 'rotation_range': 0, 'width_shift_range': 0, 'height_shift_range': 0, 'zoom_range': 0, 'brightness_range': 0, 'fill_mode': 0})\n",
        "random.shuffle(near_vector_array)\n",
        "\"\"\"\n",
        "# 最良近傍ベクトルを現在位置で初期化\n",
        "candidate_vector[\"evaluation_value\"] = 1.0\n",
        "best_near_vector = candidate_vector.copy()\n",
        "\n",
        "# %% [markdown]\n",
        "# ----\n",
        "# # # # # # # # 近傍解ループ　ここから\n",
        "\n",
        "# %% [code]\n",
        "CNN_model = None\n",
        "while(True):\n",
        "    print(\"####################################################################################################\")\n",
        "    for near_vector in near_vector_array:\n",
        "        print(near_vector)\n",
        "            \n",
        "    for near_vector in near_vector_array:\n",
        "        print(\"--------------------------------------------------------------------------------------------------\")\n",
        "        print(near_vector)\n",
        "\n",
        "        # %% [markdown]\n",
        "        # ----\n",
        "        # Create model\n",
        "\n",
        "        # %% [code]\n",
        "        # optimizerの初期化\n",
        "        #optimizer = Adam(lr=0.0001)\n",
        "        #optimizer = RMSprop(lr=2e-5) #, decay=1e-3)\n",
        "        #optimizer = SGD(lr=2e-5, momentum=0.9, decay=1e-6, nesterov=True)\n",
        "        optimizer = SGD(lr=1e-4, momentum=0.9)\n",
        "        \n",
        "        # モデルの定義\n",
        "        if value_space[\"color_mode\"][near_vector[\"color_mode\"]] == \"grayscale\":\n",
        "            num_color = 1\n",
        "        else:\n",
        "            num_color = 3\n",
        "        try:\n",
        "            CNN_model = CNN(input_shape=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],num_color),\n",
        "                            kernel_size=(value_space[\"CNN_kernel_size\"][near_vector[\"CNN_kernel_size\"]],value_space[\"CNN_kernel_size\"][near_vector[\"CNN_kernel_size\"]]),\n",
        "                            max_pooling_size=(value_space[\"CNN_max_pooling_size\"][near_vector[\"CNN_max_pooling_size\"]],value_space[\"CNN_max_pooling_size\"][near_vector[\"CNN_max_pooling_size\"]]),\n",
        "                            act_func=value_space[\"CNN_act_func\"][near_vector[\"CNN_act_func\"]],\n",
        "                            drop_ratio=value_space[\"CNN_drop_ratio\"][near_vector[\"CNN_drop_ratio\"]],\n",
        "                            num_layer=value_space[\"CNN_num_layer\"][near_vector[\"CNN_num_layer\"]],\n",
        "                            conv2d_filters=value_space[\"CNN_conv2d_filters\"][near_vector[\"CNN_conv2d_filters\"]],\n",
        "                            num_dence_layer=value_space[\"CNN_num_dence_layer\"][near_vector[\"CNN_num_dence_layer\"]],\n",
        "                            num_conv2d_layer=value_space[\"CNN_num_conv2d_layer\"][near_vector[\"CNN_num_conv2d_layer\"]],\n",
        "                           )\n",
        "        except Exception as e:\n",
        "            print(\"Skipped as ValueError was raised at CNN().\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "        \n",
        "        # モデルのコンパイル\n",
        "        CNN_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # モデル情報を表示\n",
        "        CNN_model.summary()\n",
        "        \n",
        "        # %% [code]\n",
        "        # 画像ファイル名, label情報の取得\n",
        "        train_df = pd.read_csv(train_labels_path, dtype='str')\n",
        "#        display(train_df.head())\n",
        "        train_preprocessed_dir = train_pre_dir\n",
        "        os.makedirs(train_preprocessed_dir, exist_ok=True)\n",
        "        for path in tqdm(train_df['filename']):\n",
        "            img = Image.open(train_dir + path)\n",
        "            img = img.resize((value_space[\"width_x_height\"][near_vector[\"width_x_height\"]], value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]))\n",
        "            img.save(train_preprocessed_dir + path)\n",
        "\n",
        "        # %% [code]\n",
        "        #-----------------------------------------------#\n",
        "        # ImageDataGenerator\n",
        "        #   - 画像の読み込み & 水増し(Data Augmentation)\n",
        "        #   - 学習時にリアルタイムにファイルからデータ読み込み\n",
        "        #     →Data Augmentationを行う\n",
        "        #   - Augmentationをリアルタイムに行うのでメモリを圧迫しない\n",
        "        #   - どのような変換をするかはインスタンス生成時に指定する\n",
        "        #-----------------------------------------------#\n",
        "\n",
        "        # trainデータ用インスタンス生成\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1. / 255,              # 画像の正規化\n",
        "#            rotation_range=value_space[\"rotation_range\"][near_vector[\"rotation_range\"]],             # ランダムに画像を回転 (単位：度)\n",
        "#            width_shift_range=value_space[\"width_shift_range\"][near_vector[\"width_shift_range\"]],        # ランダムに画像を水平シフト (画像横幅に対する割合を指定)\n",
        "#            height_shift_range=value_space[\"height_shift_range\"][near_vector[\"height_shift_range\"]],       # ランダムに画像を垂直シフト (画像縦幅に対する割合を指定)\n",
        "#            zoom_range=[1.0-value_space[\"zoom_range\"][near_vector[\"zoom_range\"]], 1.0+value_space[\"zoom_range\"][near_vector[\"zoom_range\"]]],        # ランダムに画像を拡縮 (下限, 上限)\n",
        "#            horizontal_flip=True,         # ランダムに画像を左右反転\n",
        "#            vertical_flip=False,           # ランダムに画像を上下反転\n",
        "#            brightness_range=[1.0-value_space[\"brightness_range\"][near_vector[\"brightness_range\"]], 1.0+value_space[\"brightness_range\"][near_vector[\"brightness_range\"]]],  # ランダムに画像を輝度変換 (下限, 上限)\n",
        "#            fill_mode=value_space[\"fill_mode\"][near_vector[\"fill_mode\"]],          # 画像変換時に生じた空白部分の埋め方 (nearestは近傍値で埋める)\n",
        "            validation_split = 0.3         # validationデータの割合\n",
        "            )\n",
        "\n",
        "        # %% [markdown]\n",
        "        # 参考リンク\n",
        "        # # - [ImageDataGenerator｜Keras公式ドキュメント](https://keras.io/ja/preprocessing/image/)  \n",
        "        # # - [Kerasによるデータ拡張｜人工知能に関する断創録](http://aidiary.hatenablog.com/entry/20161212/1481549365)\n",
        "\n",
        "        # %% [code]\n",
        "        #-----------------------------------------------#\n",
        "        # ImageDataGenerator.flow_from_dataframe\n",
        "        #   - DataFrameからデータ生成用ジェネレーター作成\n",
        "        #\n",
        "        #     dataframe  : 読み込むDataFrame\n",
        "        #     directory  : 元画像が格納されているディレクトリ名\n",
        "        #     x_col      : 画像名を表すcolumn\n",
        "        #     y_col      : ラベルを表すcolumn\n",
        "        #     target_size: 指定した画像サイズにリサイズする\n",
        "        #     batch_size : 学習時のミニバッチサイズ\n",
        "        #     class_mode : 問題設定  'binary'=二値分類\n",
        "        #     shuffle    : 画像読み込み順をシャッフルする\n",
        "        #     seed       : 乱数シード値\n",
        "        #     subset     : trainデータかvalidデータかを指定\n",
        "        #-----------------------------------------------#\n",
        "\n",
        "        # trainデータ用ジェネレーター\n",
        "        train_generator = train_datagen.flow_from_dataframe(\n",
        "                    dataframe=train_df,\n",
        "                    directory=train_preprocessed_dir,\n",
        "                    x_col='filename',\n",
        "                    y_col='label',\n",
        "                    target_size=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]),\n",
        "                    batch_size=value_space[\"batch_size\"][near_vector[\"batch_size\"]],\n",
        "                    color_mode=value_space[\"color_mode\"][near_vector[\"color_mode\"]],\n",
        "                    class_mode='binary',\n",
        "                    shuffle=True,\n",
        "                    seed=1111,\n",
        "                    subset = \"training\"\n",
        "                )\n",
        "\n",
        "        # validデータ用ジェネレーター\n",
        "        val_generator = train_datagen.flow_from_dataframe(\n",
        "                    dataframe=train_df,\n",
        "                    directory=train_preprocessed_dir,\n",
        "                    x_col='filename',\n",
        "                    y_col='label',\n",
        "                    target_size=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]),\n",
        "                    batch_size=value_space[\"batch_size\"][near_vector[\"batch_size\"]],\n",
        "                    color_mode=value_space[\"color_mode\"][near_vector[\"color_mode\"]],\n",
        "                    class_mode='binary',\n",
        "                    shuffle=True,\n",
        "                    seed=1111,\n",
        "                    subset = \"validation\"\n",
        "                )\n",
        "\n",
        "        # %% [markdown]\n",
        "        # ----\n",
        "        # Train model\n",
        "\n",
        "        # %% [code]\n",
        "        # 各Epoch終了時に呼び出すcallback\n",
        "        callbacks = []\n",
        "\n",
        "        # 学習ログをCSVに書き出す\n",
        "        callbacks.append(CSVLogger('history.csv'))\n",
        "\n",
        "        # --過学習防止用callback--\n",
        "        # patienceで指定したEpochの間, monitorの値が改善しなければ学習を打ち切る\n",
        "        #callbacks.append(EarlyStopping(patience=8, monitor='val_acc'))\n",
        "\n",
        "        # --学習率スケジューリング用callback--\n",
        "        # patienceで指定したEpochの間, monitorの値が改善しなければ\n",
        "        # 現在の学習率にfactorをかけて学習を継続する\n",
        "        callbacks.append(ReduceLROnPlateau(patience=3, monitor='val_acc',\n",
        "                                           factor=0.5, min_lr=0.00001, verbose=1))\n",
        "\n",
        "        # %% [code]\n",
        "        # 学習の実施\n",
        "        try:\n",
        "            history = CNN_model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=len(train_generator),\n",
        "                epochs=NUM_EPOCH,\n",
        "                validation_data=val_generator,\n",
        "                validation_steps=len(val_generator),\n",
        "                callbacks=callbacks,\n",
        "                verbose=2\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"Skipped as ValueError was raised at CNN_model.fit_generator()\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "        # %% [code]\n",
        "        # 学習結果の表示\n",
        "        show_fit_result(history)\n",
        "\n",
        "        # %% [markdown]\n",
        "        # ----\n",
        "        # 現在の解ベクトル評価\n",
        "\n",
        "        # %% [code]\n",
        "        # 検証データのLogLoss平均を取得して評価値とする\n",
        "        loss, acc = CNN_model.evaluate_generator(val_generator, steps=len(val_generator), verbose=0)\n",
        "        print('Test loss: %s, Test acc: %s' % (loss, acc))\n",
        "        near_vector[\"evaluation_value\"] = loss\n",
        "\n",
        "        # 全学習データを予測してLogLoss平均を評価 →過学習してまうので没\n",
        "        #preds = CNN_model.predict_generator(val_generator, steps=len(val_generator), verbose=1)\n",
        "        #print(loglossavg(train_df['label'].as_matrix(),preds))\n",
        "        #near_vector[\"evaluation_value\"] = loglossavg(train_df['label'].as_matrix(),preds)\n",
        "\n",
        "        # 最良の近傍解と比較\n",
        "        if near_vector[\"evaluation_value\"] < best_near_vector[\"evaluation_value\"]:\n",
        "            best_near_vector = near_vector.copy()\n",
        "\n",
        "        print(\"Best near vector=\")\n",
        "        print(best_near_vector)\n",
        "        print(\"Candidate vector=\")\n",
        "        print(candidate_vector)\n",
        "        \n",
        "        \n",
        "    # 現在のベクトルより良い近傍ベクトルがあれば移動し、なければ終了\n",
        "    if best_near_vector[\"evaluation_value\"] < candidate_vector[\"evaluation_value\"]:\n",
        "        print(\"Better vector found.\")\n",
        "        # 移動先の近傍ベクトルのリストを生成\n",
        "        near_vector_array = []\n",
        "        for key in best_near_vector:\n",
        "            if key == \"evaluation_value\":\n",
        "                    continue\n",
        "            if not key in fixed_variable:\n",
        "                near_vector = best_near_vector.copy()\n",
        "                near_vector[key] = (near_vector[key] + 1) % len(value_space[key])\n",
        "                near_vector_array.append(near_vector)\n",
        "\n",
        "                near_vector = best_near_vector.copy()\n",
        "                near_vector[key] = (near_vector[key] - 1) % len(value_space[key])\n",
        "                near_vector_array.append(near_vector)\n",
        "\n",
        "        # 前回の解候補を除外\n",
        "        index = 0\n",
        "        for near_vector in near_vector_array:\n",
        "            if near_vector == candidate_vector:\n",
        "                near_vector_array.remove(index)\n",
        "                break\n",
        "            index += 1\n",
        "        \n",
        "        # 移動\n",
        "        candidate_vector = best_near_vector.copy()\n",
        "        \n",
        "        \n",
        "    else:\n",
        "        # 最適化終了\n",
        "        break\n",
        "\n",
        "# %% [markdown]\n",
        "# # 近傍解ループここまで\n",
        "# # # # # # # ----\n",
        "\n",
        "# %% [code]\n",
        "#最適ベクトルで100エポックで再学習\n",
        "\n",
        "# %% [markdown]\n",
        "# ----\n",
        "# # # # # # # Make Submission\n",
        "\n",
        "# %% [code]\n",
        "# testデータ読み込み\n",
        "test_df = pd.read_csv(sample_submission_path, dtype='str')\n",
        "#display(test_df.head())\n",
        "test_preprocessed_dir = test_pre_dir\n",
        "os.makedirs(test_preprocessed_dir, exist_ok=True)\n",
        "\n",
        "# testデータ前処理\n",
        "for path in tqdm(test_df['filename']):\n",
        "    img = Image.open(test_dir + path)\n",
        "    img = img.resize((value_space[\"width_x_height\"][near_vector[\"width_x_height\"]], value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]))\n",
        "    img.save(test_preprocessed_dir + path)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_preprocessed_dir,\n",
        "            x_col='filename',\n",
        "            y_col=None,\n",
        "            target_size=(value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]],value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]]),\n",
        "            batch_size=value_space[\"batch_size\"][candidate_vector[\"batch_size\"]],\n",
        "            color_mode=value_space[\"color_mode\"][candidate_vector[\"color_mode\"]],\n",
        "            class_mode=None,\n",
        "            shuffle=False,\n",
        "            seed=1111\n",
        "        )\n",
        "\n",
        "# テストデータ予測\n",
        "preds = CNN_model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(len(test_generator))\n",
        "\n",
        "# testデータ予測結果の表示\n",
        "sns.distplot(np.reshape(preds, (-1,)))\n",
        "\n",
        "# submissionファイルの生成\n",
        "submission = pd.read_csv(sample_submission_path)\n",
        "submission['label'] = np.reshape(preds, (-1,))\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(submission)\n",
        "#submission.head()\n",
        "\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission)\n",
        "\n",
        "# %% [code]\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission)\n",
        "\n",
        "# %% [code]\n",
        "import shutil\n",
        "#shutil.rmtree(train_preprocessed_dir)\n",
        "#shutil.rmtree(test_preprocessed_dir)# %% [markdown]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using file path for Google Colaboratory.\n",
            "####################################################################################################\n",
            "{'CNN_conv2d_filters': 5, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 4, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 0, 'CNN_drop_ratio': 0, 'CNN_num_conv2d_layer': 0, 'width_x_height': 5, 'batch_size': 0, 'color_mode': 1, 'rotation_range': 10, 'width_shift_range': 2, 'height_shift_range': 2, 'zoom_range': 0, 'brightness_range': 5, 'fill_mode': 0}\n",
            "--------------------------------------------------------------------------------------------------\n",
            "{'CNN_conv2d_filters': 5, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 4, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 0, 'CNN_drop_ratio': 0, 'CNN_num_conv2d_layer': 0, 'width_x_height': 5, 'batch_size': 0, 'color_mode': 1, 'rotation_range': 10, 'width_shift_range': 2, 'height_shift_range': 2, 'zoom_range': 0, 'brightness_range': 5, 'fill_mode': 0}\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Model)  (None, 9, 9, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 124416)            0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               31850752  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 86,187,745\n",
            "Trainable params: 86,127,201\n",
            "Non-trainable params: 60,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f48f625600a34d40865a9480d3177c8a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Found 11900 validated image filenames belonging to 2 classes.\n",
            "Found 5100 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/30\n",
            " - 1711s - loss: 0.0949 - acc: 0.9636 - val_loss: 0.0292 - val_acc: 0.9898\n",
            "Epoch 2/30\n",
            " - 1634s - loss: 0.0394 - acc: 0.9868 - val_loss: 0.0237 - val_acc: 0.9914\n",
            "Epoch 3/30\n",
            " - 1634s - loss: 0.0267 - acc: 0.9913 - val_loss: 0.0228 - val_acc: 0.9925\n",
            "Epoch 4/30\n",
            " - 1633s - loss: 0.0233 - acc: 0.9920 - val_loss: 0.0210 - val_acc: 0.9924\n",
            "Epoch 5/30\n",
            " - 1629s - loss: 0.0150 - acc: 0.9941 - val_loss: 0.0209 - val_acc: 0.9929\n",
            "Epoch 6/30\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}