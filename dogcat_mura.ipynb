{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogcat_mura.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muraryu/dogcat/blob/master/dogcat_mura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlyuWq63uwTM",
        "colab_type": "text"
      },
      "source": [
        "Google Colabの場合のみ最初に実行する\n",
        "\n",
        "ここではGoogleドライブから必要なデータを持ってくる(直接アップロードでも良いが面倒。KaggleAPIキーも面倒。)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpPRPlu0xPeQ",
        "colab_type": "code",
        "outputId": "0cce9f8c-ed54-4b82-aff2-5e650d6c67b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# 事前にGoogleドライブに必要なデータを保存しておく\n",
        "# => train_label.csv, sample_submission.csv, train.zip, test.zip\n",
        "\n",
        "# Googleドライブのマウント\n",
        "# 実行後、標準出力のURLをクリックしてアクセス許可＆認証コードを取得し、’Enter your authorization code:’に入力する\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Googleドライブに保存しておいた重いデータのみローカルにコピー\n",
        "!cp \"drive/My Drive/dogcat/input/train.zip\" ./\n",
        "!cp \"drive/My Drive/dogcat/input/test.zip\" ./\n",
        "!cp \"drive/My Drive/dogcat/input/original/test_original.zip\" ./\n",
        "\n",
        "# 解凍\n",
        "# 標準出力を '> /dev/null' で捨てないとブラウザが固まるため注意する\n",
        "# 同様に解凍後のフォルダを左のファイルビューで展開しないこと(ファイルが多すぎて固まる)\n",
        "!mkdir ./train\n",
        "!mkdir ./test\n",
        "!mkdir ./test_original\n",
        "!unzip train.zip -d ./train > /dev/null\n",
        "!unzip test.zip -d ./test > /dev/null\n",
        "!unzip test_original.zip -d ./test_original > /dev/null\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9B-6y2p59zZ",
        "colab_type": "code",
        "outputId": "142ab290-94f9-4c7c-a2fb-70be8b686a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# パス　実行環境ごとに書き換え\n",
        "train_dir = 'train/'\n",
        "test_dir = 'test/'\n",
        "test_original_dir = 'test_original/'\n",
        "train_pre_dir = 'train_pre/'\n",
        "test_pre_dir = 'test_pre/'\n",
        "test_original_pre_dir = 'test_original_pre/'\n",
        "train_labels_path = 'drive/My Drive/dogcat/input/train_label.csv'\n",
        "sample_submission_path = 'drive/My Drive/dogcat/input/sample_submission.csv'\n",
        "sample_submission_original_path = 'drive/My Drive/dogcat/input/original/sample_submission_original.csv'\n",
        "gradcam_dir = 'drive/My Drive/dogcat/GradCAM++/'\n",
        "model_check_point_dir = 'drive/My Drive/dogcat/model/'\n",
        "\n",
        "# Google Colaboratory環境であることを示すフラグ\n",
        "google_colab_flag = []\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofv8fEIltxB0",
        "colab_type": "text"
      },
      "source": [
        "##################\n",
        "\n",
        "**ここからKaggle共通**\n",
        "##################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b43dpyJyxAUR",
        "colab_type": "code",
        "outputId": "d97e4a11-d820-49d0-cb64-2526acbe6669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Google Colaboratory環境ではない場合、Kaggleのファイルパスを使用\n",
        "if 'google_colab_flag' in locals():\n",
        "    print('Using file path for Google Colaboratory.')\n",
        "else:\n",
        "    print('Using file path for Kaggle.')\n",
        "    train_dir = '../input/train/'\n",
        "    test_dir = '../input/test/'\n",
        "    train_pre_dir = '../train_pre/'\n",
        "    test_pre_dir = '../test_pre/'\n",
        "    train_labels_path = '../input/train_label.csv'\n",
        "    sample_submission_path = '../input/sample_submission.csv'\n",
        "    gradcam_dir = '../GradCAM++'\n",
        "    model_check_point_dir = './model/'\n",
        "\n",
        "# %% [markdown]\n",
        "# 事前に画像サイズを統一しておくことで学習時間を短縮します。 \n",
        "\n",
        "# %% [markdown]\n",
        "# ********# Dogs vs Cats Recognition: InClass\n",
        "# # # # # # # # これは [Dogs vs Cats Recognition: InClass](https://www.kaggle.com/c/dog-cat-recognition/overview)のBase kernelです。  \n",
        "# # # # # # # # PythonのDeep learning用フレームワーク keras を使用し、基本的なCNNモデルを構築します。  \n",
        "# # # # # # # # またkerasの ImageDataGenerator を使用し、画像の水増し (Data Augmentation) を行えるようにしているのがポイントです。\n",
        "\n",
        "# %% [markdown]\n",
        "# ----\n",
        "# # # # # # # # Import, Config, Utilities\n",
        "# # # # # # # # まず初めに下記を行います。\n",
        "# # # # # # # # - 必要なライブラリのImport\n",
        "# # # # # # # # - 各種Config (乱数seed設定, 学習パラメタ...etc)\n",
        "# # # # # # # # - Utility関数の定義\n",
        "\n",
        "# %% [code]\n",
        "# 必要なライブラリのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D, BatchNormalization, Activation\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger, ModelCheckpoint\n",
        "\n",
        "from IPython.display import HTML\n",
        "import base64\n",
        "\n",
        "# 追加\n",
        "import math\n",
        "from keras.applications import *\n",
        "import traceback\n",
        "\n",
        "# %% [code]\n",
        "# 関数\n",
        "\n",
        "# 学習曲線の描画関数\n",
        "def show_fit_result(history):\n",
        "    plt.figure(figsize=(16,4))\n",
        "    \n",
        "    # plot accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['acc'], label='trn_acc', marker='.')\n",
        "    plt.plot(history.history['val_acc'], label='val_acc', marker='.')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "    \n",
        "    # plot loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='trn_loss', marker='.')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss', marker='.')\n",
        "    plt.title('Crossentropy')\n",
        "    plt.legend()\n",
        "\n",
        "def CNN(input_shape, kernel_size, max_pooling_size, act_func, conv2d_filters, drop_ratio, num_layer, num_dence_layer, num_conv2d_layer):\n",
        "    # input_shape      : 入力次元数 \n",
        "    # kernel_size      : 畳み込み層のフィルタサイズ\n",
        "    # max_pooling_size : Pooling層のフィルタサイズ\n",
        "    # act_func         : 中間層の活性化関数\n",
        "    # drop_ratio       : Dropoutの割合\n",
        "    \n",
        "    # kernel initializers\n",
        "    gl_init = glorot_uniform(1111)\n",
        "    \n",
        "    # Sequentialモデルのインスタンス作成\n",
        "    model = Sequential()\n",
        "\n",
        "    \"\"\"\n",
        "    for i in range(num_layer):\n",
        "        for j in range(num_conv2d_layer):\n",
        "            if i == 0 and j == 0:\n",
        "                model.add(Conv2D(conv2d_filters, kernel_size, activation='relu', input_shape=input_shape, kernel_initializer=gl_init))\n",
        "            else:\n",
        "                model.add(Conv2D(conv2d_filters, kernel_size, activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "        model.add(Dropout(drop_ratio, seed=1111))\n",
        "\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "        \n",
        "    for i in range(num_dence_layer):\n",
        "        model.add(Dense(int(1024/(2**i)), activation='relu', kernel_initializer=gl_init))\n",
        "    # 出力層\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    model.add(Conv2D(64, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init, input_shape=input_shape))\n",
        "    model.add(Conv2D(64, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(128, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(128, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(256, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(256, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(256, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, kernel_size, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(Conv2D(512, 1, activation='relu', padding='same', kernel_initializer=gl_init))\n",
        "    model.add(MaxPooling2D(pool_size=max_pooling_size))\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(256, activation='relu', kernel_initializer=gl_init))\n",
        "    model.add(Dropout(0.5, seed=1111))\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "    \"\"\"\n",
        "    \n",
        "    #conv_base = Xception(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = VGG16(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = VGG19(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    conv_base = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
        "    #conv_base = MobileNet(input_shape=input_shape, alpha=1.0, depth_multiplier=1, dropout=1e-3, include_top=False, weights='imagenet', pooling=None)\n",
        "    #conv_base = DenseNet201(include_top=False, weights='imagenet', input_shape=input_shape, pooling=None)\n",
        "    #conv_base = NASNetLarge(input_shape=input_shape, include_top=False, weights='imagenet', pooling=None)\n",
        "    #conv_base = MobileNetV2(input_shape=input_shape, alpha=1.0, depth_multiplier=1, include_top=False, weights='imagenet', pooling=None)\n",
        "    \n",
        "    #conv_base.trainable = False\n",
        "    model.add(conv_base)\n",
        "#    model.add(Flatten())\n",
        "\n",
        "#    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(256))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dropout(0.5, seed=1111))\n",
        "    model.add(Dense(1, activation='sigmoid')) \n",
        "\n",
        "    \n",
        "    \"\"\"\n",
        "    # 畳み込み層、Pooling層、Dropoutの追加\n",
        "    model.add(Conv2D(64, kernel_size, padding='same', activation=act_func, input_shape=input_shape, kernel_initializer=gl_init))\n",
        "    model.add(MaxPool2D(pool_size=max_pooling_size))\n",
        "    model.add(Dropout(drop_ratio, seed=1111))\n",
        "    \n",
        "    # 畳み込み層、Pooling層、Dropoutの追加\n",
        "    for i in range(num_layer):    \n",
        "        model.add(Conv2D(64, kernel_size, padding='same', activation=act_func, kernel_initializer=gl_init))\n",
        "        model.add(MaxPool2D(pool_size=max_pooling_size))\n",
        "        model.add(Dropout(drop_ratio, seed=1111))\n",
        "\n",
        "    # 2次元-->1次元への変換\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    # 全結合層の追加\n",
        "    model.add(Dense(128, activation=act_func, kernel_initializer=gl_init))\n",
        "    \n",
        "    # 出力層\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer=gl_init))\n",
        "    \"\"\"\n",
        "    \n",
        "    return model\n",
        "    \n",
        "def logloss(true_label, predicted, eps=1e-15):\n",
        "    p = np.clip(predicted, eps, 1 - eps)\n",
        "    true_label = int(true_label)\n",
        "    if true_label == 1:\n",
        "        return -math.log(p)\n",
        "    else:\n",
        "        return -math.log(1 - p)\n",
        "\n",
        "def loglossavg(true_label_ary, predicted_ary):\n",
        "    s = 0\n",
        "    i = 0\n",
        "    print(true_label_ary)\n",
        "    print(predicted_ary)\n",
        "    for true_label in true_label_ary:\n",
        "        s += logloss(true_label, predicted_ary[i])\n",
        "        i += 1\n",
        "    return s/i\n",
        "\n",
        "# (参考)下記関数を使うと、予測結果のCSVファイルをCommitなしで取得できます。\n",
        "# https://www.kaggle.com/rtatman/download-a-csv-file-from-a-kernel\n",
        "# function that takes in a dataframe and creates a text link to  \n",
        "# download it (will only work for files < 2MB or so)\n",
        "def create_download_link(df, title = \"Download CSV file\", filename = \"submission.csv\"):  \n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
        "    html = html.format(payload=payload,title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "\n",
        "### **注意**\n",
        "# # # # # # 上記で乱数seedを固定することで、ある程度は実験の再現性が得られますが、完全ではありません。  \n",
        "# # # # # # (kernel編集中の学習結果とCommit後の学習結果が微妙に異なる)  \n",
        "# # # # # # これはNVIDIA製GPUにおける並列計算処理が非決定的であるためです。  \n",
        "# # # # # # 本kernelの最後にはCommitなしで予測結果のCSVをダウンロードする方法も記載していますので参考にしてください。\n",
        "\n",
        "# 乱数seedの固定 (kerasの学習結果の再現性確保)\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(1111)\n",
        "random.seed(1111)\n",
        "\n",
        "session_conf = tf.ConfigProto(\n",
        "    intra_op_parallelism_threads=1,\n",
        "    inter_op_parallelism_threads=1\n",
        ")\n",
        "\n",
        "tf.set_random_seed(1111)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# %% [code]\n",
        "# 変数\n",
        "\n",
        "value_space = {}\n",
        "\n",
        "# CNNパラメータ\n",
        "value_space[\"CNN_conv2d_filters\"] = [4,8,16,32,64,128,192,256,512,1024,2048,4096,8192]\n",
        "value_space[\"CNN_num_dence_layer\"] = [0,1,2,3,4,5,6,7]\n",
        "value_space[\"CNN_num_layer\"] = np.arange(0, 11, 1)\n",
        "value_space[\"CNN_kernel_size\"] = np.arange(1, 11, 1)\n",
        "value_space[\"CNN_act_func\"] = [\"softmax\", \"elu\", \"selu\", \"softplus\", \"softsign\", \"relu\", \"tanh\", \"sigmoid\", \"hard_sigmoid\", \"linear\"]\n",
        "value_space[\"CNN_max_pooling_size\"] = np.arange(2, 11, 1)\n",
        "value_space[\"CNN_drop_ratio\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"CNN_num_conv2d_layer\"] = [1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# target size\n",
        "value_space[\"width_x_height\"] = [32,64,96,128,192,512,320,384,448,512]\n",
        "value_space[\"batch_size\"] = [8,16,32,48,128,256,512,1024,2048]\n",
        "value_space[\"color_mode\"] = [\"grayscale\", \"rgb\"]\n",
        "\n",
        "# 学習画像前処理\n",
        "value_space[\"rotation_range\"] = np.arange(0, 181, 5)\n",
        "value_space[\"width_shift_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"height_shift_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"zoom_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"brightness_range\"] = np.arange(0.0, 1.1, 0.1)\n",
        "value_space[\"fill_mode\"] = [\"nearest\", \"reflect\", \"wrap\"]\n",
        "\n",
        "# ベクトル初期化\n",
        "candidate_vector = {\n",
        "    \"CNN_conv2d_filters\":5,\n",
        "    \"CNN_num_dence_layer\":3,\n",
        "    \"CNN_num_layer\":4,\n",
        "    \"CNN_kernel_size\":2,\n",
        "    \"CNN_act_func\":5,\n",
        "    \"CNN_max_pooling_size\":0,\n",
        "    \"CNN_drop_ratio\":0,\n",
        "    \"CNN_num_conv2d_layer\":0,\n",
        "\n",
        "    \"width_x_height\":5,\n",
        "    \"batch_size\":0,\n",
        "    \"color_mode\":1,\n",
        "\n",
        "    \"rotation_range\":10,\n",
        "    \"width_shift_range\":2,\n",
        "    \"height_shift_range\":2,\n",
        "    \"zoom_range\":0,\n",
        "    \"brightness_range\":5,\n",
        "    \"fill_mode\":0,\n",
        "    }\n",
        "\n",
        "# 固定変数リスト\n",
        "fixed_variable = [\n",
        "    \"CNN_conv2d_filters\",\n",
        "    \"CNN_num_dence_layer\",\n",
        "    \"CNN_num_layer\",\n",
        "    \"CNN_kernel_size\",\n",
        "    \"CNN_act_func\",\n",
        "    \"CNN_max_pooling_size\",\n",
        "    \"CNN_drop_ratio\",\n",
        "    \"CNN_num_conv2d_layer\",\n",
        "\n",
        "    \"width_x_height\",\n",
        "    \"batch_size\",\n",
        "    \"color_mode\",\n",
        "\n",
        "    \"rotation_range\",\n",
        "    \"width_shift_range\",\n",
        "    \"height_shift_range\",\n",
        "    \"zoom_range\",\n",
        "    \"brightness_range\",\n",
        "    \"fill_mode\",\n",
        "]\n",
        "\n",
        "\n",
        "# number of epoch\n",
        "NUM_EPOCH = 15\n",
        "\n",
        "# %% [code]\n",
        "# 初回近傍ベクトル\n",
        "near_vector_array = []\n",
        "\n",
        "near_vector_array.append(candidate_vector.copy())\n",
        "for key in candidate_vector:\n",
        "    if not key in fixed_variable:\n",
        "        near_vector = candidate_vector.copy()\n",
        "        near_vector[key] = (near_vector[key] + 1) % len(value_space[key])\n",
        "        near_vector_array.append(near_vector)\n",
        "\n",
        "        near_vector = candidate_vector.copy()\n",
        "        near_vector[key] = (near_vector[key] - 1) % len(value_space[key])\n",
        "        near_vector_array.append(near_vector)\n",
        "\n",
        "\"\"\"\n",
        "near_vector_array.append({'CNN_conv2d_filters': 3, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 0, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 1, 'CNN_drop_ratio': 10, 'width': 5, 'height': 5, 'batch_size': 2, 'color_mode': 1, 'rotation_range': 0, 'width_shift_range': 0, 'height_shift_range': 0, 'zoom_range': 0, 'brightness_range': 0, 'fill_mode': 0})\n",
        "near_vector_array.append({'CNN_conv2d_filters': 3, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 0, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 1, 'CNN_drop_ratio': 10, 'width': 5, 'height': 5, 'batch_size': 2, 'color_mode': 1, 'rotation_range': 0, 'width_shift_range': 0, 'height_shift_range': 0, 'zoom_range': 0, 'brightness_range': 0, 'fill_mode': 0})\n",
        "random.shuffle(near_vector_array)\n",
        "\"\"\"\n",
        "# 最良近傍ベクトルを現在位置で初期化\n",
        "candidate_vector[\"evaluation_value\"] = 1.0\n",
        "best_near_vector = candidate_vector.copy()\n",
        "\n",
        "# %% [markdown]\n",
        "# ----\n",
        "# # # # # # # # 近傍解ループ　ここから\n",
        "\n",
        "# %% [code]\n",
        "CNN_model = None\n",
        "while(True):\n",
        "    print(\"####################################################################################################\")\n",
        "    for near_vector in near_vector_array:\n",
        "        print(near_vector)\n",
        "            \n",
        "    for near_vector in near_vector_array:\n",
        "        print(\"--------------------------------------------------------------------------------------------------\")\n",
        "        print(near_vector)\n",
        "\n",
        "        # %% [markdown]\n",
        "        # ----\n",
        "        # Create model\n",
        "\n",
        "        # %% [code]\n",
        "        # optimizerの初期化\n",
        "        #optimizer = Adam(lr=0.0001)\n",
        "        #optimizer = RMSprop(lr=2e-5) #, decay=1e-3)\n",
        "        #optimizer = SGD(lr=2e-5, momentum=0.9, decay=1e-6, nesterov=True)\n",
        "        optimizer = SGD(lr=1e-4, momentum=0.9)\n",
        "        \n",
        "        # モデルの定義\n",
        "        if value_space[\"color_mode\"][near_vector[\"color_mode\"]] == \"grayscale\":\n",
        "            num_color = 1\n",
        "        else:\n",
        "            num_color = 3\n",
        "        try:\n",
        "            CNN_model = CNN(input_shape=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],num_color),\n",
        "                            kernel_size=(value_space[\"CNN_kernel_size\"][near_vector[\"CNN_kernel_size\"]],value_space[\"CNN_kernel_size\"][near_vector[\"CNN_kernel_size\"]]),\n",
        "                            max_pooling_size=(value_space[\"CNN_max_pooling_size\"][near_vector[\"CNN_max_pooling_size\"]],value_space[\"CNN_max_pooling_size\"][near_vector[\"CNN_max_pooling_size\"]]),\n",
        "                            act_func=value_space[\"CNN_act_func\"][near_vector[\"CNN_act_func\"]],\n",
        "                            drop_ratio=value_space[\"CNN_drop_ratio\"][near_vector[\"CNN_drop_ratio\"]],\n",
        "                            num_layer=value_space[\"CNN_num_layer\"][near_vector[\"CNN_num_layer\"]],\n",
        "                            conv2d_filters=value_space[\"CNN_conv2d_filters\"][near_vector[\"CNN_conv2d_filters\"]],\n",
        "                            num_dence_layer=value_space[\"CNN_num_dence_layer\"][near_vector[\"CNN_num_dence_layer\"]],\n",
        "                            num_conv2d_layer=value_space[\"CNN_num_conv2d_layer\"][near_vector[\"CNN_num_conv2d_layer\"]],\n",
        "                           )\n",
        "        except Exception as e:\n",
        "            print(\"Skipped as ValueError was raised at CNN().\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "        \n",
        "        # モデルのコンパイル\n",
        "        CNN_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # モデル情報を表示\n",
        "        CNN_model.summary()\n",
        "        \n",
        "        if not NUM_EPOCH == 0:\n",
        "            # %% [code]\n",
        "            # 画像ファイル名, label情報の取得\n",
        "            train_df = pd.read_csv(train_labels_path, dtype='str')\n",
        "    #        display(train_df.head())\n",
        "            train_preprocessed_dir = train_pre_dir\n",
        "            os.makedirs(train_preprocessed_dir, exist_ok=True)\n",
        "            for path in tqdm(train_df['filename']):\n",
        "                img = Image.open(train_dir + path)\n",
        "                img = img.resize((value_space[\"width_x_height\"][near_vector[\"width_x_height\"]], value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]))\n",
        "                img.save(train_preprocessed_dir + path)\n",
        "\n",
        "            # %% [code]\n",
        "            #-----------------------------------------------#\n",
        "            # ImageDataGenerator\n",
        "            #   - 画像の読み込み & 水増し(Data Augmentation)\n",
        "            #   - 学習時にリアルタイムにファイルからデータ読み込み\n",
        "            #     →Data Augmentationを行う\n",
        "            #   - Augmentationをリアルタイムに行うのでメモリを圧迫しない\n",
        "            #   - どのような変換をするかはインスタンス生成時に指定する\n",
        "            #-----------------------------------------------#\n",
        "\n",
        "            # trainデータ用インスタンス生成\n",
        "            train_datagen = ImageDataGenerator(\n",
        "                rescale=1. / 255,              # 画像の正規化\n",
        "    #            rotation_range=value_space[\"rotation_range\"][near_vector[\"rotation_range\"]],             # ランダムに画像を回転 (単位：度)\n",
        "    #            width_shift_range=value_space[\"width_shift_range\"][near_vector[\"width_shift_range\"]],        # ランダムに画像を水平シフト (画像横幅に対する割合を指定)\n",
        "    #            height_shift_range=value_space[\"height_shift_range\"][near_vector[\"height_shift_range\"]],       # ランダムに画像を垂直シフト (画像縦幅に対する割合を指定)\n",
        "    #            zoom_range=[1.0-value_space[\"zoom_range\"][near_vector[\"zoom_range\"]], 1.0+value_space[\"zoom_range\"][near_vector[\"zoom_range\"]]],        # ランダムに画像を拡縮 (下限, 上限)\n",
        "    #            horizontal_flip=True,         # ランダムに画像を左右反転\n",
        "    #            vertical_flip=False,           # ランダムに画像を上下反転\n",
        "    #            brightness_range=[1.0-value_space[\"brightness_range\"][near_vector[\"brightness_range\"]], 1.0+value_space[\"brightness_range\"][near_vector[\"brightness_range\"]]],  # ランダムに画像を輝度変換 (下限, 上限)\n",
        "    #            fill_mode=value_space[\"fill_mode\"][near_vector[\"fill_mode\"]],          # 画像変換時に生じた空白部分の埋め方 (nearestは近傍値で埋める)\n",
        "                validation_split = 0.3         # validationデータの割合\n",
        "                )\n",
        "\n",
        "            # %% [markdown]\n",
        "            # 参考リンク\n",
        "            # # - [ImageDataGenerator｜Keras公式ドキュメント](https://keras.io/ja/preprocessing/image/)  \n",
        "            # # - [Kerasによるデータ拡張｜人工知能に関する断創録](http://aidiary.hatenablog.com/entry/20161212/1481549365)\n",
        "\n",
        "            # %% [code]\n",
        "            #-----------------------------------------------#\n",
        "            # ImageDataGenerator.flow_from_dataframe\n",
        "            #   - DataFrameからデータ生成用ジェネレーター作成\n",
        "            #\n",
        "            #     dataframe  : 読み込むDataFrame\n",
        "            #     directory  : 元画像が格納されているディレクトリ名\n",
        "            #     x_col      : 画像名を表すcolumn\n",
        "            #     y_col      : ラベルを表すcolumn\n",
        "            #     target_size: 指定した画像サイズにリサイズする\n",
        "            #     batch_size : 学習時のミニバッチサイズ\n",
        "            #     class_mode : 問題設定  'binary'=二値分類\n",
        "            #     shuffle    : 画像読み込み順をシャッフルする\n",
        "            #     seed       : 乱数シード値\n",
        "            #     subset     : trainデータかvalidデータかを指定\n",
        "            #-----------------------------------------------#\n",
        "\n",
        "            # trainデータ用ジェネレーター\n",
        "            train_generator = train_datagen.flow_from_dataframe(\n",
        "                        dataframe=train_df,\n",
        "                        directory=train_preprocessed_dir,\n",
        "                        x_col='filename',\n",
        "                        y_col='label',\n",
        "                        target_size=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]),\n",
        "                        batch_size=value_space[\"batch_size\"][near_vector[\"batch_size\"]],\n",
        "                        color_mode=value_space[\"color_mode\"][near_vector[\"color_mode\"]],\n",
        "                        class_mode='binary',\n",
        "                        shuffle=True,\n",
        "                        seed=1111,\n",
        "                        subset = \"training\"\n",
        "                    )\n",
        "\n",
        "            # validデータ用ジェネレーター\n",
        "            val_generator = train_datagen.flow_from_dataframe(\n",
        "                        dataframe=train_df,\n",
        "                        directory=train_preprocessed_dir,\n",
        "                        x_col='filename',\n",
        "                        y_col='label',\n",
        "                        target_size=(value_space[\"width_x_height\"][near_vector[\"width_x_height\"]],value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]),\n",
        "                        batch_size=value_space[\"batch_size\"][near_vector[\"batch_size\"]],\n",
        "                        color_mode=value_space[\"color_mode\"][near_vector[\"color_mode\"]],\n",
        "                        class_mode='binary',\n",
        "                        shuffle=True,\n",
        "                        seed=1111,\n",
        "                        subset = \"validation\"\n",
        "                    )\n",
        "\n",
        "            # %% [code]\n",
        "            # 各Epoch終了時に呼び出すcallback\n",
        "            callbacks = []\n",
        "\n",
        "            # 学習ログをCSVに書き出す\n",
        "            callbacks.append(CSVLogger('history.csv'))\n",
        "\n",
        "            # --過学習防止用callback--\n",
        "            # patienceで指定したEpochの間, monitorの値が改善しなければ学習を打ち切る\n",
        "            #callbacks.append(EarlyStopping(patience=8, monitor='val_acc'))\n",
        "\n",
        "            # --学習率スケジューリング用callback--\n",
        "            # patienceで指定したEpochの間, monitorの値が改善しなければ\n",
        "            # 現在の学習率にfactorをかけて学習を継続する\n",
        "            callbacks.append(ReduceLROnPlateau(patience=3, monitor='val_acc',\n",
        "                                              factor=0.5, min_lr=1e-5, verbose=1))\n",
        "\n",
        "            # --エポックごとに経過保存callback--\n",
        "            os.makedirs(model_check_point_dir, exist_ok=True)\n",
        "            callbacks.append(ModelCheckpoint(filepath = os.path.join(model_check_point_dir,'cnn_model-epoch{epoch:02d}-loss{loss:.4f}-acc{acc:.4f}-vloss{val_loss:.4f}-vacc{val_acc:.4f}.hdf5'), monitor='val_loss', verbose=1, save_best_only=False, mode='auto'))\n",
        "\n",
        "        # 重みロード\n",
        "        #weight_path = '/content/drive/My Drive/dogcat/model/cnn_model-epoch06-loss0.0244-acc0.9949-vloss0.0114-vacc0.9959.hdf5'\n",
        "        #CNN_model.load_weights(weight_path)\n",
        "        #print('Using weight file : ' + weight_path)\n",
        "\n",
        "        if NUM_EPOCH == 0:\n",
        "            print('break without fit (NUM_EPOCH == 0)')\n",
        "            break\n",
        "\n",
        "        # %% [code]\n",
        "        # 学習の実施\n",
        "        try:\n",
        "            history = CNN_model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=len(train_generator),\n",
        "                epochs=NUM_EPOCH,\n",
        "                validation_data=val_generator,\n",
        "                validation_steps=len(val_generator),\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"Skipped as ValueError was raised at CNN_model.fit_generator()\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "        # 学習結果の表示\n",
        "        show_fit_result(history)\n",
        "\n",
        "        # 現在の解ベクトル評価\n",
        "\n",
        "        # 検証データのLogLoss平均を取得して評価値とする\n",
        "        loss, acc = CNN_model.evaluate_generator(val_generator, steps=len(val_generator), verbose=1)\n",
        "        print('Test loss: %s, Test acc: %s' % (loss, acc))\n",
        "        near_vector[\"evaluation_value\"] = loss\n",
        "\n",
        "        # LogLoss平均\n",
        "        #print(loglossavg(train_df['label'].as_matrix(),preds))\n",
        "\n",
        "        # 最良の近傍解と比較\n",
        "        if near_vector[\"evaluation_value\"] < best_near_vector[\"evaluation_value\"]:\n",
        "            best_near_vector = near_vector.copy()\n",
        "\n",
        "        print(\"Best near vector=\")\n",
        "        print(best_near_vector)\n",
        "        print(\"Candidate vector=\")\n",
        "        print(candidate_vector)\n",
        "        \n",
        "        \n",
        "    # 現在のベクトルより良い近傍ベクトルがあれば移動し、なければ終了\n",
        "    if best_near_vector[\"evaluation_value\"] < candidate_vector[\"evaluation_value\"]:\n",
        "        print(\"Better vector found.\")\n",
        "        # 移動先の近傍ベクトルのリストを生成\n",
        "        near_vector_array = []\n",
        "        for key in best_near_vector:\n",
        "            if key == \"evaluation_value\":\n",
        "                    continue\n",
        "            if not key in fixed_variable:\n",
        "                near_vector = best_near_vector.copy()\n",
        "                near_vector[key] = (near_vector[key] + 1) % len(value_space[key])\n",
        "                near_vector_array.append(near_vector)\n",
        "\n",
        "                near_vector = best_near_vector.copy()\n",
        "                near_vector[key] = (near_vector[key] - 1) % len(value_space[key])\n",
        "                near_vector_array.append(near_vector)\n",
        "\n",
        "        # 前回の解候補を除外\n",
        "        index = 0\n",
        "        for near_vector in near_vector_array:\n",
        "            if near_vector == candidate_vector:\n",
        "                near_vector_array.remove(index)\n",
        "                break\n",
        "            index += 1\n",
        "        \n",
        "        # 移動\n",
        "        candidate_vector = best_near_vector.copy()\n",
        "        \n",
        "        \n",
        "    else:\n",
        "        # 最適化終了\n",
        "        break\n",
        "\n",
        "# %% [markdown]\n",
        "# # 近傍解ループここまで\n",
        "# # # # # # # ----\n",
        "\n",
        "# %% [code]\n",
        "#最適ベクトルで100エポックで再学習"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using file path for Google Colaboratory.\n",
            "####################################################################################################\n",
            "{'CNN_conv2d_filters': 5, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 4, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 0, 'CNN_drop_ratio': 0, 'CNN_num_conv2d_layer': 0, 'width_x_height': 5, 'batch_size': 0, 'color_mode': 1, 'rotation_range': 10, 'width_shift_range': 2, 'height_shift_range': 2, 'zoom_range': 0, 'brightness_range': 5, 'fill_mode': 0}\n",
            "--------------------------------------------------------------------------------------------------\n",
            "{'CNN_conv2d_filters': 5, 'CNN_num_dence_layer': 3, 'CNN_num_layer': 4, 'CNN_kernel_size': 2, 'CNN_act_func': 5, 'CNN_max_pooling_size': 0, 'CNN_drop_ratio': 0, 'CNN_num_conv2d_layer': 0, 'width_x_height': 5, 'batch_size': 0, 'color_mode': 1, 'rotation_range': 10, 'width_shift_range': 2, 'height_shift_range': 2, 'zoom_range': 0, 'brightness_range': 5, 'fill_mode': 0}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Model)  (None, 1536)              54336736  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               393472    \n",
            "_________________________________________________________________\n",
            "batch_normalization_407 (Bat (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_407 (Activation)  (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 54,731,489\n",
            "Trainable params: 54,670,433\n",
            "Non-trainable params: 61,056\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b488013b511452f98e0d1b6949ca514",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Found 11900 validated image filenames belonging to 2 classes.\n",
            "Found 5100 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/15\n",
            "1488/1488 [==============================] - 3478s 2s/step - loss: 0.1636 - acc: 0.9367 - val_loss: 0.0330 - val_acc: 0.9902\n",
            "\n",
            "Epoch 00001: saving model to drive/My Drive/dogcat/model/cnn_model-epoch01-loss0.1636-acc0.9366-vloss0.0330-vacc0.9902.hdf5\n",
            "Epoch 2/15\n",
            "1488/1488 [==============================] - 3428s 2s/step - loss: 0.0874 - acc: 0.9712 - val_loss: 0.0238 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00002: saving model to drive/My Drive/dogcat/model/cnn_model-epoch02-loss0.0874-acc0.9712-vloss0.0238-vacc0.9929.hdf5\n",
            "Epoch 3/15\n",
            "1488/1488 [==============================] - 3416s 2s/step - loss: 0.0666 - acc: 0.9777 - val_loss: 0.0217 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00003: saving model to drive/My Drive/dogcat/model/cnn_model-epoch03-loss0.0666-acc0.9777-vloss0.0217-vacc0.9929.hdf5\n",
            "Epoch 4/15\n",
            "1488/1488 [==============================] - 3460s 2s/step - loss: 0.0629 - acc: 0.9823 - val_loss: 0.0246 - val_acc: 0.9908\n",
            "\n",
            "Epoch 00004: saving model to drive/My Drive/dogcat/model/cnn_model-epoch04-loss0.0629-acc0.9823-vloss0.0246-vacc0.9908.hdf5\n",
            "Epoch 5/15\n",
            "1488/1488 [==============================] - 3479s 2s/step - loss: 0.0536 - acc: 0.9844 - val_loss: 0.0165 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00005: saving model to drive/My Drive/dogcat/model/cnn_model-epoch05-loss0.0536-acc0.9844-vloss0.0165-vacc0.9939.hdf5\n",
            "Epoch 6/15\n",
            " 196/1488 [==>...........................] - ETA: 44:06 - loss: 0.0362 - acc: 0.9885"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP-BFVjAoxD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#テストデータ予測＆submissionファイル作成\n",
        "print('Creating submission.csv...')\n",
        "\n",
        "# testデータ読み込み\n",
        "test_df = pd.read_csv(sample_submission_path, dtype='str')\n",
        "#display(test_df.head())\n",
        "test_preprocessed_dir = test_pre_dir\n",
        "os.makedirs(test_preprocessed_dir, exist_ok=True)\n",
        "\n",
        "# testデータ前処理\n",
        "for path in tqdm(test_df['filename']):\n",
        "    img = Image.open(test_dir + path)\n",
        "\n",
        "    # 正方形になるように余白追加\n",
        "    width, height = img.size\n",
        "    if height == width:\n",
        "        #print('height == width')\n",
        "        pass\n",
        "    elif height > width:\n",
        "        #print('height > width')\n",
        "        img = img.crop((-(height-width)/2, 0, width+(height-width)/2, height))\n",
        "    else:\n",
        "        #print('height < width')\n",
        "        img = img.crop((0, -((width-height)/2), width, height+(width-height)/2))\n",
        "\n",
        "    img = img.resize((value_space[\"width_x_height\"][near_vector[\"width_x_height\"]], value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]))\n",
        "    img.save(test_preprocessed_dir + path)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_preprocessed_dir,\n",
        "            x_col='filename',\n",
        "            y_col=None,\n",
        "            target_size=(value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]],value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]]),\n",
        "            batch_size=value_space[\"batch_size\"][candidate_vector[\"batch_size\"]],\n",
        "            color_mode=value_space[\"color_mode\"][candidate_vector[\"color_mode\"]],\n",
        "            class_mode=None,\n",
        "            shuffle=False,\n",
        "            seed=1111\n",
        "        )\n",
        "\n",
        "# テストデータ予測\n",
        "preds = CNN_model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(len(test_generator))\n",
        "\n",
        "# testデータ予測結果の表示\n",
        "sns.distplot(np.reshape(preds, (-1,)))\n",
        "\n",
        "# submissionファイルの生成\n",
        "submission = pd.read_csv(sample_submission_path)\n",
        "submission['label'] = np.reshape(preds, (-1,))\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(submission)\n",
        "#submission.head()\n",
        "\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission)\n",
        "\n",
        "# %% [code]\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission)\n",
        "\n",
        "# %% [code]\n",
        "import shutil\n",
        "#shutil.rmtree(train_preprocessed_dir)\n",
        "#shutil.rmtree(test_preprocessed_dir)# %% [markdown]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDGxUIv2Q7az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binning & 確信度が低いファイル名表示\n",
        "import csv\n",
        "\n",
        "outary = []\n",
        "with open('submission.csv', 'r') as fin:\n",
        "  reader = csv.reader(fin)\n",
        "  header = next(reader)\n",
        "  outary.append(header)\n",
        "\n",
        "  b0 = 0\n",
        "  b1 = 0\n",
        "  b2 = 0\n",
        "  for row in reader:\n",
        "    if float(row[1]) > 0.01 and float(row[1]) < 0.99 :\n",
        "      b0 += 1\n",
        "      print(str(b0), ' : ', row)\n",
        "      row[1] = 0.5\n",
        "    elif float(row[1]) <= 0.01:\n",
        "      row[1] = 0.0001 # 0にして間違うとLogLoss無限になる\n",
        "    else:\n",
        "      row[1] = 0.9999 # 1にして間違うとLogLoss無限になる\n",
        "#   print(row[1])\n",
        "    outary.append(row)\t\n",
        "\n",
        "with open('submission_step.csv', 'w') as fout:\n",
        "    writer = csv.writer(fout, lineterminator='\\n')\n",
        "    writer.writerows(outary)\n",
        "fout.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fN3cmcg3x3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grad-CAM++による判断根拠可視化\n",
        "# CNNの最終畳み込み層を指定する必要あり\n",
        "# 事前にCNN_modelに学習済みCNNモデルを入れておく\n",
        "# 以下は活性化関数が２階微分で０になることが前提\n",
        "# https://qiita.com/Dason08/items/a8013b3fa4d303f5c41c\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import argparse\n",
        "import keras\n",
        "import time\n",
        "import sys\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "def Grad_Cam_plus_plus(input_model, layer_name, x, row, col):\n",
        "    '''\n",
        "    Args:\n",
        "       input_model: ResNet50のモデル\n",
        "       x: 画像(array)\n",
        "       layer_name: 畳み込み層の名前\n",
        "       (row, col): 画像のサイズ\n",
        "    Returns:\n",
        "       jetcam: 影響の大きい箇所を色付けした画像(array)\n",
        "    '''\n",
        "\n",
        "    model = input_model\n",
        "\n",
        "    #前処理\n",
        "    X = np.expand_dims(x, axis=0)\n",
        "    X = X.astype('float32')\n",
        "    preprocessed_input = X / 255.0\n",
        "\n",
        "\n",
        "    #予測クラスの算出\n",
        "    predictions = model.predict(preprocessed_input)\n",
        "    class_idx = np.argmax(predictions[0])\n",
        "\n",
        "    #使用する重みの抽出、高階微分の計算\n",
        "    class_output = model.layers[-1].output\n",
        "    conv_output = model.get_layer(layer_name).get_output_at(1) # ImageNetのInceptionResNetV2の場合は1\n",
        "    grads = K.gradients(class_output, conv_output)[0]\n",
        "    #first_derivative：１階微分\n",
        "    first_derivative = K.exp(class_output)[0][class_idx] * grads\n",
        "    #second_derivative：２階微分\n",
        "    second_derivative = K.exp(class_output)[0][class_idx] * grads * grads\n",
        "    #third_derivative：３階微分\n",
        "    third_derivative = K.exp(class_output)[0][class_idx] * grads * grads * grads\n",
        "\n",
        "    #関数の定義\n",
        "    gradient_function = K.function([model.input], [conv_output, first_derivative, second_derivative, third_derivative])  # model.inputを入力すると、conv_outputとgradsを出力する関数\n",
        "\n",
        "\n",
        "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = gradient_function([preprocessed_input])\n",
        "    conv_output, conv_first_grad, conv_second_grad, conv_third_grad = conv_output[0], conv_first_grad[0], conv_second_grad[0], conv_third_grad[0]\n",
        "\n",
        "    #alphaを求める\n",
        "    global_sum = np.sum(conv_output.reshape((-1, conv_first_grad.shape[2])), axis=0)\n",
        "    alpha_num = conv_second_grad\n",
        "    alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((1,1,conv_first_grad.shape[2]))\n",
        "    alpha_denom = np.where(alpha_denom!=0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
        "    alphas = alpha_num / alpha_denom\n",
        "\n",
        "    #alphaの正規化\n",
        "    alpha_normalization_constant = np.sum(np.sum(alphas, axis = 0), axis = 0)\n",
        "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
        "    alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad.shape[2]))\n",
        "\n",
        "    #wの計算\n",
        "    weights = np.maximum(conv_first_grad, 0.0)\n",
        "    deep_linearization_weights = np.sum((weights * alphas).reshape((-1, conv_first_grad.shape[2])))\n",
        "\n",
        "    #Lの計算\n",
        "    grad_CAM_map = np.sum(deep_linearization_weights * conv_output, axis=2)\n",
        "    grad_CAM_map = np.maximum(grad_CAM_map, 0)\n",
        "    grad_CAM_map = grad_CAM_map / np.max(grad_CAM_map)\n",
        "\n",
        "    #ヒートマップを描く\n",
        "    grad_CAM_map = cv2.resize(grad_CAM_map, (row, col), cv2.INTER_LINEAR)\n",
        "    jetcam = cv2.applyColorMap(np.uint8(255 * grad_CAM_map), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
        "    jetcam = (np.float32(jetcam) + x / 2)   # もとの画像に合成\n",
        "\n",
        "    return jetcam\n",
        "\n",
        "#image_path = test_pre_dir + '493.jpg' # Target image file path\n",
        "#image_path = './train/cat.4289.jpg'\n",
        "image_path = './crop.jpg'\n",
        "#image_path = './drive/My Drive/dogcat/input/20190614182430.JPG'\n",
        "\n",
        "target_layer = 'inception_resnet_v2' # InceptionResNetV2\n",
        "row = value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]\n",
        "col = value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]\n",
        "\n",
        "img = img_to_array(load_img(image_path,target_size=(row,col)))\n",
        "img_GCAMplusplus = Grad_Cam_plus_plus(CNN_model, target_layer, img, row, col)\n",
        "time = time.ctime()\n",
        "img_Gplusplusname = gradcam_dir +os.path.basename(image_path) + \"_GCAM++.jpg\"\n",
        "os.makedirs(gradcam_dir, exist_ok=True)\n",
        "cv2.imwrite(img_Gplusplusname, img_GCAMplusplus)\n",
        "\n",
        "def hconcat_resize_min(im_list, interpolation=cv2.INTER_CUBIC):\n",
        "    h_min = min(im.shape[0] for im in im_list)\n",
        "    im_list_resize = [cv2.resize(im, (int(im.shape[1] * h_min / im.shape[0]), h_min), interpolation=interpolation)\n",
        "                      for im in im_list]\n",
        "    return cv2.hconcat(im_list_resize)\n",
        "\n",
        "original_image = cv2.cvtColor(cv2.resize(cv2.imread(image_path), (row,col)), cv2.COLOR_BGR2RGB)\n",
        "gradcam_image = cv2.cvtColor(cv2.imread(img_Gplusplusname), cv2.COLOR_BGR2RGB)\n",
        "im_h_resize = hconcat_resize_min([original_image, gradcam_image])\n",
        "plt.imshow(im_h_resize)\n",
        "print('Heat Map')\n",
        "\n",
        "# 予測\n",
        "img_predict = []\n",
        "try:\n",
        "    img = Image.open(image_path)  # 画像読み込み\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((row, col))  # 画像のリサイズ\n",
        "    img_array = np.asarray(img)\n",
        "    img_predict.append(img_array)\n",
        "except Exception as e:\n",
        "    pass\n",
        "img_predict = np.asarray(img_predict) / 255.\n",
        "result_predict = CNN_model.predict(img_predict)\n",
        "print('prob = ', result_predict[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAnb58EqNtN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 転移学習の場合は以下を実行して最後の方の畳み込み層を見つける\n",
        "print(CNN_model.get_layer('inception_resnet_v2').get_output_at(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5gZsc_yUf1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデル保存\n",
        "CNN_model.save('drive/My Drive/dogcat/model/cnn_model-')\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mZd7XKimos2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 二つの結果ファイルをマージ\n",
        "submission1_path = 'submission (1).csv'\n",
        "submission2_path = 'submission_original.csv'\n",
        "\n",
        "import csv\n",
        "\n",
        "outary = []\n",
        "\n",
        "data_array = []\n",
        "data = []\n",
        "\n",
        "with open(submission1_path, 'r') as fin:\n",
        "\t  reader = csv.reader(fin)\n",
        "\t  header = next(reader)\n",
        "\t  outary.append(header)\n",
        "\t  for row in reader:\n",
        "\t\t    data.append(row)\n",
        "\n",
        "data_array.append(data)\n",
        "data = []\n",
        "\n",
        "with open(submission2_path, 'r') as fin:\n",
        "    reader = csv.reader(fin)\n",
        "    header = next(reader)\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "data_array.append(data)\n",
        "\n",
        "'''\n",
        "for irow in range(len(data)):\n",
        "    max_conf = 0.\n",
        "    max_data_row = None\n",
        "    for temp_data in data_array:\n",
        "        if abs(float(temp_data[irow][1]) - 0.5) >= max_conf:\n",
        "            max_conf = abs(float(temp_data[irow][1]) - 0.5)\n",
        "            max_data_row = temp_data[irow]\n",
        "    outary.append(max_data_row)\n",
        "'''\n",
        "\n",
        "count = 0\n",
        "data_priority = 0\n",
        "for irow in range(len(data)):\n",
        "    row = data_array[data_priority][irow]\n",
        "    if float(row[1]) > 0.01 and float(row[1]) < 0.99 :\n",
        "      count += 1\n",
        "      print(str(count), ' : ', row)\n",
        "      row[1] = (float(row[1]) + float(data_array[data_priority+1][irow][1]))/2\n",
        "      print(str(count), ' : ', row)\n",
        "    outary.append(row)\n",
        "\n",
        "with open('submission_merge.csv', 'w') as fout:\n",
        "    writer = csv.writer(fout, lineterminator='\\n')\n",
        "    writer.writerows(outary)\n",
        "fout.close()\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDDrrjBaHe2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#本家テストデータ予測＆submissionファイル作成\n",
        "print('Creating submission_original.csv...')\n",
        "\n",
        "# 本家testデータ読み込み\n",
        "test_original_df = pd.read_csv(sample_submission_original_path, dtype='str')\n",
        "#display(test_df.head())\n",
        "test_original_preprocessed_dir = test_original_pre_dir\n",
        "os.makedirs(test_original_preprocessed_dir, exist_ok=True)\n",
        "\n",
        "# 本家testデータ前処理\n",
        "for path in tqdm(test_original_df['filename']):\n",
        "    img = Image.open(test_original_dir + path)\n",
        "\n",
        "    # 正方形になるように余白追加\n",
        "    width, height = img.size\n",
        "    if height == width:\n",
        "        #print('height == width')\n",
        "        pass\n",
        "    elif height > width:\n",
        "        #print('height > width')\n",
        "        img = img.crop((-(height-width)/2, 0, width+(height-width)/2, height))\n",
        "    else:\n",
        "        #print('height < width')\n",
        "        img = img.crop((0, -((width-height)/2), width, height+(width-height)/2))\n",
        "\n",
        "    img = img.resize((value_space[\"width_x_height\"][near_vector[\"width_x_height\"]], value_space[\"width_x_height\"][near_vector[\"width_x_height\"]]))\n",
        "    img.save(test_original_preprocessed_dir + path)\n",
        "\n",
        "test_original_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_original_generator = test_original_datagen.flow_from_dataframe(\n",
        "            dataframe=test_original_df,\n",
        "            directory=test_original_preprocessed_dir,\n",
        "            x_col='filename',\n",
        "            y_col=None,\n",
        "            target_size=(value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]],value_space[\"width_x_height\"][candidate_vector[\"width_x_height\"]]),\n",
        "            batch_size=value_space[\"batch_size\"][candidate_vector[\"batch_size\"]],\n",
        "            color_mode=value_space[\"color_mode\"][candidate_vector[\"color_mode\"]],\n",
        "            class_mode=None,\n",
        "            shuffle=False,\n",
        "            seed=1111\n",
        "        )\n",
        "\n",
        "# 本家テストデータ予測\n",
        "preds = CNN_model.predict_generator(test_original_generator, steps=len(test_original_generator), verbose=1)\n",
        "print(len(test_original_generator))\n",
        "\n",
        "# 本家testデータ予測結果の表示\n",
        "sns.distplot(np.reshape(preds, (-1,)))\n",
        "\n",
        "# submissionファイルの生成\n",
        "submission_original = pd.read_csv(sample_submission_original_path)\n",
        "submission_original['label'] = np.reshape(preds, (-1,))\n",
        "submission_original.to_csv('submission_original.csv', index=False)\n",
        "print(submission_original)\n",
        "#submission.head()\n",
        "\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission_original)\n",
        "\n",
        "# %% [code]\n",
        "# (参考)CSVダウンロードリンクの生成\n",
        "create_download_link(submission_original)\n",
        "\n",
        "# %% [code]\n",
        "import shutil\n",
        "#shutil.rmtree(train_preprocessed_dir)\n",
        "#shutil.rmtree(test_original_preprocessed_dir)# %% [markdown]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNEvPtaDTkZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像読み込み\n",
        "img = Image.open(\"train/cat.4289.jpg\")\n",
        "width, height = img.size\n",
        "print(img.size)\n",
        "\n",
        "# img[top : bottom, left : right]\n",
        "# サンプル1の切り出し、保存\n",
        "img1 = None\n",
        "if height == width:\n",
        "    print('height == width')\n",
        "    img1 = img\n",
        "elif height > width:\n",
        "    print('height > width')\n",
        "    img1 = img.crop((-(height-width)/2, 0, width+(height-width)/2, height))\n",
        "else:\n",
        "    print('height < width')\n",
        "    img1 = img.crop((0, -((width-height)/2), width, height+(width-height)/2))\n",
        "img1.save(\"crop.jpg\")\n",
        "plt.imshow(np.array(img1))\n",
        "print(img1.size)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}